[{"abstractive": {"id": "Bmr019.s.1", "text": "The Berkeley Meeting Recorder group discussed efforts to train and test the Aurora group's HTK-based recognition system on ICSI's digits corpus.", "type": "abstract"}, "extractive": [{"id": "Bmr019.B.dialogueact144", "speaker": "B", "starttime": "230.407", "startwordid": "Bmr019.w.1,108", "endtime": "247.411", "endwordid": "Bmr019.w.1,171", "text": "And the interesting thing is that even though , <vocalsound> yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , <vocalsound> it 's just not as good as having a <disfmarker> a l very large amount of data and training up a <disfmarker> a <disfmarker> a nice good big <vocalsound> HMM .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.2", "text": "Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data.", "type": "abstract"}, "extractive": [{"id": "Bmr019.E.dialogueact12", "speaker": "E", "starttime": "12.133", "startwordid": "Bmr019.w.59", "endtime": "18.592", "endwordid": "Bmr019.w.78", "text": "Two items , which was , uh , digits and possibly stuff on <disfmarker> on , uh , forced alignment ,", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "5a", "channel": "c4"}}, {"id": "Bmr019.A.dialogueact892", "speaker": "A", "starttime": "1901.51", "startwordid": "Bmr019.w.8,419", "endtime": "1905.68", "endwordid": "Bmr019.w.8,437", "text": "So we <disfmarker> we only r hav I only looked at actually alignments from one meeting that we chose ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.3", "text": "Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers.", "type": "abstract"}, "extractive": [{"id": "Bmr019.B.dialogueact205", "speaker": "B", "starttime": "384.422", "startwordid": "Bmr019.w.1,725", "endtime": "395.563", "endwordid": "Bmr019.w.1,763", "text": "Uh , but the other is that , um , the digits <vocalsound> recorded here in this room with these close mikes , i uh , are actually a lot harder than the <pause> studio - recording TI - digits .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}, {"id": "Bmr019.F.dialogueact287", "speaker": "F", "starttime": "560.942", "startwordid": "Bmr019.w.2,528", "endtime": "568.312", "endwordid": "Bmr019.w.2,552", "text": "If you have only one utterance per speaker you might actually screw up on estimating the <disfmarker> the warping , uh , factor .", "label": "s^e", "original_label": "s^e", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "58a+", "channel": "c5"}}, {"id": "Bmr019.G.dialogueact941", "speaker": "G", "starttime": "1995.83", "startwordid": "Bmr019.w.8,866", "endtime": "1998.93", "endwordid": "Bmr019.w.8,881", "text": "Well , I know there were some speaker labelling problems , um , after interruptions .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me001", "adjacency": "23b", "channel": "c8"}}, {"id": "Bmr019.G.dialogueact975", "speaker": "G", "starttime": "2034.96", "startwordid": "Bmr019.w.9,139", "endtime": "2037.78", "endwordid": "Bmr019.w.9,155", "text": "But you 're actually saying that certain , uh , speakers were mis mis - identified .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me001", "adjacency": "33a", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr019.s.4", "text": "While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work.", "type": "abstract"}, "extractive": [{"id": "Bmr019.A.dialogueact667", "speaker": "A", "starttime": "1351.96", "startwordid": "Bmr019.w.6,066", "endtime": "1365.35", "endwordid": "Bmr019.w.6,096", "text": "and <disfmarker> and <disfmarker> W we <disfmarker> we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors <pause> that were occurring", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact761", "speaker": "A", "starttime": "1634.42", "startwordid": "Bmr019.w.7,119", "endtime": "1638.48", "endwordid": "Bmr019.w.7,134", "text": "So just sort of working through a bunch of debugging kinds of issues .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.5", "text": "The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly.", "type": "abstract"}, "extractive": [{"id": "Bmr019.F.dialogueact617", "speaker": "F", "starttime": "1224.11", "startwordid": "Bmr019.w.5,609", "endtime": "1232.46", "endwordid": "Bmr019.w.5,633", "text": "So <disfmarker> so the key <pause> thing that 's missing here is basically the ability to feed , you know , other features <vocalsound> i into the recognizer", "label": "s^bu", "original_label": "s^bu", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "1b.2a", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact618", "speaker": "F", "starttime": "1232.46", "startwordid": "Bmr019.w.5,634", "endtime": "1234.4", "endwordid": "Bmr019.w.5,641", "text": "and also then to train the system .", "label": "s^bu^e", "original_label": "s^bu^e", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "1b+.2a+", "channel": "c5"}}, {"id": "Bmr019.B.dialogueact605", "speaker": "B", "starttime": "1188.41", "startwordid": "Bmr019.w.5,473", "endtime": "1193.29", "endwordid": "Bmr019.w.5,484", "text": "we want to <vocalsound> have the ability to feed it different features .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "67b++", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.6", "text": "For comparing Meeting Recorder digits results, it was decided that the Aurora HTK-based system should be tested on data from the TI digits corpus.", "type": "decisions"}, "extractive": [{"id": "Bmr019.B.dialogueact184", "speaker": "B", "starttime": "357.375", "startwordid": "Bmr019.w.1,559", "endtime": "361.105", "endwordid": "Bmr019.w.1,578", "text": "Yeah , bu although I 'd be <disfmarker> I think it 'd be interesting to just take this exact actual system", "label": "s^bk|s^cs^ng", "original_label": "s^bk|s^cs^ng", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "41b.42a", "channel": "c1"}}, {"id": "Bmr019.B.dialogueact188", "speaker": "B", "starttime": "362.475", "startwordid": "Bmr019.w.1,585", "endtime": "363.785", "endwordid": "Bmr019.w.1,593", "text": "and try it out on TI - digits .", "label": "s^cs^e", "original_label": "s^cs^e", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "41b++.42a++", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.7", "text": "The script for extracting speaker ID information will require modifications to obtain a more accurate estimation of the amount of data recorded per speaker.", "type": "decisions"}, "extractive": [{"id": "Bmr019.F.dialogueact307", "speaker": "F", "starttime": "607.467", "startwordid": "Bmr019.w.2,724", "endtime": "619.074", "endwordid": "Bmr019.w.2,758", "text": "So , we might have to modify that script to recognize the , um , speakers , <vocalsound> um , in the <disfmarker> in the , uh , um , <vocalsound> TI - digits <pause> database .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.E.dialogueact315", "speaker": "E", "starttime": "633.64", "startwordid": "Bmr019.w.2,815", "endtime": "637.91", "endwordid": "Bmr019.w.2,833", "text": "because we may have to do an extract to get the <pause> amount of data per speaker about right .", "label": "s^df", "original_label": "s^df", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "1b+", "channel": "c4"}}]}, {"abstractive": {"id": "Bmr019.s.8", "text": "Subsequent recognition experiments will look at large vocabulary speech from a far-field microphone (as performed in Switchboard evaluations).", "type": "decisions"}, "extractive": [{"id": "Bmr019.B.dialogueact470", "speaker": "B", "starttime": "890.822", "startwordid": "Bmr019.w.4,078", "endtime": "903.549", "endwordid": "Bmr019.w.4,119", "text": "Yeah . I <disfmarker> I know what I was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of the <disfmarker> the large vocabulary speech from a far microphone ,", "label": "fg|s", "original_label": "fg|s", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "33a", "channel": "c1"}}, {"id": "Bmr019.B.dialogueact483", "speaker": "B", "starttime": "928.346", "startwordid": "Bmr019.w.4,243", "endtime": "934.941", "endwordid": "Bmr019.w.4,267", "text": "But I 'm saying if you do the same kind of limited thing <vocalsound> as people have done in Switchboard evaluations or as <disfmarker> a", "label": "s^cs^df.%-", "original_label": "s^cs^df.%-", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "36a", "channel": "c1"}}, {"id": "Bmr019.E.dialogueact489", "speaker": "E", "starttime": "941.69", "startwordid": "Bmr019.w.4,311", "endtime": "945.27", "endwordid": "Bmr019.w.4,333", "text": "Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ?", "label": "s^bu", "original_label": "s^bu", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "39b.40a", "channel": "c4"}}, {"id": "Bmr019.E.dialogueact493", "speaker": "E", "starttime": "947.86", "startwordid": "Bmr019.w.4,354", "endtime": "949.81", "endwordid": "Bmr019.w.4,365", "text": "but you use the acoustics from the far - field mike .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "41a+", "channel": "c4"}}]}, {"abstractive": {"id": "Bmr019.s.9", "text": "Hand-marked, word-level alignments are needed to reveal speaker boundaries and tune the parameters of the model.", "type": "decisions"}, "extractive": [{"id": "Bmr019.F.dialogueact781", "speaker": "F", "starttime": "1683.66", "startwordid": "Bmr019.w.7,333", "endtime": "1688.42", "endwordid": "Bmr019.w.7,348", "text": "So , <vocalsound> we would need a hand - marked , um , <vocalsound> word - level alignments", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "24a", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact782", "speaker": "F", "starttime": "1688.48", "startwordid": "Bmr019.w.7,349", "endtime": "1692.78", "endwordid": "Bmr019.w.7,366", "text": "or at least sort of the boundaries of the speech betw you know , between the speakers .", "label": "s^cs^e", "original_label": "s^cs^e", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "24a+", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact784", "speaker": "F", "starttime": "1695.61", "startwordid": "Bmr019.w.7,376", "endtime": "1701.33", "endwordid": "Bmr019.w.7,395", "text": "and tune the parameters of the <disfmarker> of the model , uh , to op to get the best <pause> performance .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "24a+++", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr019.s.10", "text": "Modifications to the Transcriber tool are required for allowing transcribers to simultaneously view the signal in XWaves and see where words are located in time.", "type": "decisions"}, "extractive": [{"id": "Bmr019.A.dialogueact847", "speaker": "A", "starttime": "1820.8", "startwordid": "Bmr019.w.8,000", "endtime": "1824.96", "endwordid": "Bmr019.w.8,024", "text": "You know , interface - wise if you 're looking at speech , you wanna be able to know really where the words are .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "3a", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact851", "speaker": "A", "starttime": "1829.19", "startwordid": "Bmr019.w.8,055", "endtime": "1834.58", "endwordid": "Bmr019.w.8,072", "text": "um , and see if you can in maybe incorporate it into the Transcriber tool some way ,", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "4a+", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact877", "speaker": "A", "starttime": "1870.28", "startwordid": "Bmr019.w.8,272", "endtime": "1877.51", "endwordid": "Bmr019.w.8,305", "text": "Yeah , it wou the advantage would just be that when you brought up a bin you would be able <disfmarker> if you were zoomed in enough in Transcriber to see all the words ,", "label": "fg|s", "original_label": "fg|s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "9b", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact879", "speaker": "A", "starttime": "1877.51", "startwordid": "Bmr019.w.8,306", "endtime": "1880.53", "endwordid": "Bmr019.w.8,322", "text": "you would be able to , like , have the words sort of located in time ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "10a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.12", "text": "A significant loss in recognition resulted from not having included the type of phone-loop adaptation found in the SRI system.", "type": "problems"}, "extractive": [{"id": "Bmr019.B.dialogueact145", "speaker": "B", "starttime": "247.411", "startwordid": "Bmr019.w.1,172", "endtime": "250.991", "endwordid": "Bmr019.w.1,190", "text": "Um , also you had the adaptation in the SRI system , which we didn't have in this .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}, {"id": "Bmr019.F.dialogueact155", "speaker": "F", "starttime": "264.75", "startwordid": "Bmr019.w.1,248", "endtime": "268.3", "endwordid": "Bmr019.w.1,259", "text": "So there was a significant loss from not doing the adaptation .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr019.s.13", "text": "Recognition performance was worse for digits recorded in closed microphone conditions versus those recorded in a studio (e.g. TI-digits).", "type": "problems"}, "extractive": [{"id": "Bmr019.B.dialogueact205", "speaker": "B", "starttime": "384.422", "startwordid": "Bmr019.w.1,725", "endtime": "395.563", "endwordid": "Bmr019.w.1,763", "text": "Uh , but the other is that , um , the digits <vocalsound> recorded here in this room with these close mikes , i uh , are actually a lot harder than the <pause> studio - recording TI - digits .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.14", "text": "A mismatch between the manner in which data were collected and the models used for doing recognition---e.g. bandwidth parameterization and the use of near- versus far-field microphones---was identified.", "type": "problems"}, "extractive": [{"id": "Bmr019.B.dialogueact205", "speaker": "B", "starttime": "384.422", "startwordid": "Bmr019.w.1,725", "endtime": "395.563", "endwordid": "Bmr019.w.1,763", "text": "Uh , but the other is that , um , the digits <vocalsound> recorded here in this room with these close mikes , i uh , are actually a lot harder than the <pause> studio - recording TI - digits .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}, {"id": "Bmr019.F.dialogueact240", "speaker": "F", "starttime": "479.25", "startwordid": "Bmr019.w.2,134", "endtime": "489.66", "endwordid": "Bmr019.w.2,173", "text": "I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "48a", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact361", "speaker": "F", "starttime": "744.345", "startwordid": "Bmr019.w.3,267", "endtime": "750.595", "endwordid": "Bmr019.w.3,289", "text": "That 's where the most m acoustic mismatch is between the currently used models and the <disfmarker> the r the set up here .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "9a", "channel": "c5"}}, {"id": "Bmr019.B.dialogueact411", "speaker": "B", "starttime": "810.93", "startwordid": "Bmr019.w.3,652", "endtime": "812.02", "endwordid": "Bmr019.w.3,656", "text": "the near versus far .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.15", "text": "Too little data per speaker can have a negative effect on VTL estimation.", "type": "problems"}, "extractive": [{"id": "Bmr019.F.dialogueact287", "speaker": "F", "starttime": "560.942", "startwordid": "Bmr019.w.2,528", "endtime": "568.312", "endwordid": "Bmr019.w.2,552", "text": "If you have only one utterance per speaker you might actually screw up on estimating the <disfmarker> the warping , uh , factor .", "label": "s^e", "original_label": "s^e", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "58a+", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr019.s.16", "text": "The PZM channel selected for obtaining digits data was too far away from most of the speakers.", "type": "problems"}, "extractive": [{"id": "Bmr019.E.dialogueact547", "speaker": "E", "starttime": "1066.65", "startwordid": "Bmr019.w.4,893", "endtime": "1069.24", "endwordid": "Bmr019.w.4,905", "text": "Because it 's further away from most of the people reading digits .", "label": "s^df", "original_label": "s^df", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "55a", "channel": "c4"}}]}, {"abstractive": {"id": "Bmr019.s.17", "text": "Current speech alignment techniques assume that foreground speech must be continuous and, barring some isolated words and backchannels, can not cope with overlapping background speech.", "type": "problems"}, "extractive": [{"id": "Bmr019.F.dialogueact701", "speaker": "F", "starttime": "1467.78", "startwordid": "Bmr019.w.6,469", "endtime": "1474.79", "endwordid": "Bmr019.w.6,492", "text": "you know , as Liz said the <disfmarker> we f enforce the fact that , uh , the foreground speech has to be continuous .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.A.dialogueact707", "speaker": "A", "starttime": "1495.69", "startwordid": "Bmr019.w.6,572", "endtime": "1504.25", "endwordid": "Bmr019.disfmarker.314", "text": "things like words that do occur just by themselves <pause> a alone , like backchannels or something that we did allow to have background speech around it <disfmarker>", "label": "s.%--", "original_label": "s.%--", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact709", "speaker": "A", "starttime": "1504.6", "startwordid": "Bmr019.w.6,600", "endtime": "1505.8", "endwordid": "Bmr019.w.6,607", "text": "those would be able to do that ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact711", "speaker": "A", "starttime": "1505.8", "startwordid": "Bmr019.w.6,608", "endtime": "1507.56", "endwordid": "Bmr019.w.6,614", "text": "but the rest would be constrained .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.18", "text": "Performing adaptations on both the foreground and background speaker produced a new variety of misalignments, a problem resulting, in part, from the fact that background speakers often match better to foreground conditionss.", "type": "problems"}, "extractive": [{"id": "Bmr019.A.dialogueact736", "speaker": "A", "starttime": "1571.17", "startwordid": "Bmr019.w.6,869", "endtime": "1574.39", "endwordid": "Bmr019.w.6,879", "text": "We probably want to adapt at least the foreground speaker .", "label": "s^cs^rt", "original_label": "s^cs^rt", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact737", "speaker": "A", "starttime": "1574.39", "startwordid": "Bmr019.w.6,880", "endtime": "1579.01", "endwordid": "Bmr019.w.6,895", "text": "But , I guess Andreas tried adapting both the foreground and a background generic speaker ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "20a", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact738", "speaker": "A", "starttime": "1579.01", "startwordid": "Bmr019.w.6,896", "endtime": "1582.41", "endwordid": "Bmr019.w.6,908", "text": "and that 's actually a little bit of a f funky model .", "label": "s^ba", "original_label": "s^ba", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "20a+", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact739", "speaker": "A", "starttime": "1582.41", "startwordid": "Bmr019.w.6,909", "endtime": "1584.19", "endwordid": "Bmr019.w.6,917", "text": "Like , it gives you some weird alignments ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "20a++", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact740", "speaker": "A", "starttime": "1584.19", "startwordid": "Bmr019.w.6,918", "endtime": "1588.24", "endwordid": "Bmr019.w.6,933", "text": "just because often the background speakers match better to the foreground than the foreground speaker .", "label": "s^df", "original_label": "s^df", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "20a++", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.19", "text": "Transcribers occasionally misidentified speakers and omitted backchannels that were more hidden in the mixed signal.", "type": "problems"}, "extractive": [{"id": "Bmr019.A.dialogueact1679", "speaker": "A", "starttime": "3171.04", "startwordid": "Bmr019.w.14,769", "endtime": "3180.63", "endwordid": "Bmr019.w.14,804", "text": "Tha - There are some cases like where the <disfmarker> the wrong speaker <disfmarker> uh , these ca Not a lot , but where the <disfmarker> the wrong person <disfmarker> the <disfmarker> the speech is addre attached to the wrong speaker", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "39b+.40a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.20", "text": "Good recognition performance was achieved with the lapel microphones.", "type": "progress"}, "extractive": [{"id": "Bmr019.E.dialogueact90", "speaker": "E", "starttime": "121.753", "startwordid": "Bmr019.w.581", "endtime": "127.063", "endwordid": "Bmr019.w.602", "text": "I mean that it was basically <disfmarker> the only thing that was even slightly surprising was that the lapel did so well .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c4"}}]}, {"abstractive": {"id": "Bmr019.s.21", "text": "The recognizer performed well on time-aligned segments labelled as 'non-overlap' (i.e. one person talking), while segments labelled as 'overlap' (i.e. multiple speakers talking at the same time) yielded poor results.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact503", "speaker": "A", "starttime": "989.34", "startwordid": "Bmr019.w.4,504", "endtime": "994.01", "endwordid": "Bmr019.w.4,519", "text": "In the H L T paper we took <pause> segments that are channel <disfmarker> time - aligned ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "43b", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact506", "speaker": "A", "starttime": "998.296", "startwordid": "Bmr019.w.4,535", "endtime": "1003.19", "endwordid": "Bmr019.w.4,550", "text": "and we took cases where the transcribers said there was only one person talking here ,", "label": "s:s", "original_label": "s:s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "44a", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact508", "speaker": "A", "starttime": "1007.37", "startwordid": "Bmr019.w.4,562", "endtime": "1008.77", "endwordid": "Bmr019.w.4,570", "text": "and called that \" non - overlap \" .", "label": "s:s", "original_label": "s:s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "44a++", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact514", "speaker": "A", "starttime": "1013.27", "startwordid": "Bmr019.w.4,595", "endtime": "1017.04", "endwordid": "Bmr019.w.4,606", "text": "The bad numbers were from <pause> the segments where there was overlap .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "47a+", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.22", "text": "Future recognition efforts will include looking at reverberation.", "type": "progress"}, "extractive": [{"id": "Bmr019.B.dialogueact613", "speaker": "B", "starttime": "1208.16", "startwordid": "Bmr019.w.5,556", "endtime": "1219.72", "endwordid": "Bmr019.w.5,590", "text": "And then , um , uh , also Dave is <disfmarker> is thinking about using the data in different ways , uh , to <vocalsound> um , uh , explicitly work on reverberation", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.23", "text": "Forced alignment improvements were gained by examining the types of errors generated and making the necessary adjustments.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact667", "speaker": "A", "starttime": "1351.96", "startwordid": "Bmr019.w.6,066", "endtime": "1365.35", "endwordid": "Bmr019.w.6,096", "text": "and <disfmarker> and <disfmarker> W we <disfmarker> we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors <pause> that were occurring", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.24", "text": "More accurate alignments were achieved by significantly increasing the pruning value.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact686", "speaker": "A", "starttime": "1431.35", "startwordid": "Bmr019.w.6,328", "endtime": "1434.07", "endwordid": "Bmr019.w.6,337", "text": "Actually it was better with <disfmarker> slightly better or about th", "label": "s^ng.%--", "original_label": "s^ng.%--", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "15b.16a", "channel": "c0"}}, {"id": "Bmr019.F.dialogueact694", "speaker": "F", "starttime": "1445.01", "startwordid": "Bmr019.w.6,391", "endtime": "1452.15", "endwordid": "Bmr019.w.6,415", "text": "Um , but it turned out for <disfmarker> for <disfmarker> to get accurate alignments it was really important to open up the pruning significantly .", "label": "fg|s", "original_label": "fg|s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact699", "speaker": "F", "starttime": "1461.22", "startwordid": "Bmr019.w.6,449", "endtime": "1464.84", "endwordid": "Bmr019.w.6,460", "text": "Um , <vocalsound> so that was one big factor that helped improve things", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr019.s.25", "text": "Future alignment efforts will include cloning the reject model, and adapting it to both the foreground and background speaker.", "type": "progress"}, "extractive": [{"id": "Bmr019.F.dialogueact749", "speaker": "F", "starttime": "1599.43", "startwordid": "Bmr019.w.6,982", "endtime": "1608.09", "endwordid": "Bmr019.w.7,013", "text": "And you <disfmarker> and what we wanted to try with <disfmarker> you know , once we have this paper written and have a little more time , <vocalsound> uh , t cloning that reject model", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact750", "speaker": "F", "starttime": "1608.09", "startwordid": "Bmr019.w.7,014", "endtime": "1613.65", "endwordid": "Bmr019.w.7,034", "text": "and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact752", "speaker": "F", "starttime": "1614.72", "startwordid": "Bmr019.w.7,040", "endtime": "1617.66", "endwordid": "Bmr019.w.7,051", "text": "and the other copy would be adapted to the background speaker .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr019.s.26", "text": "Members of the group will also compare Meeting Recorder data with other corpora (e.g. Switchboard) to determine whether speaker overlap is a feature that is more specific to meetings versus other modes of spoken interaction.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact1063", "speaker": "A", "starttime": "2190.27", "startwordid": "Bmr019.w.9,988", "endtime": "2198.56", "endwordid": "Bmr019.w.10,018", "text": "We were <disfmarker> I guess the other thing we 're <disfmarker> we 're <disfmarker> I should say is that we 're gonna , um try <disfmarker> compare this type of overlap analysis to Switchboard ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "46a", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact1067", "speaker": "A", "starttime": "2200.3", "startwordid": "Bmr019.w.10,025", "endtime": "2208.19", "endwordid": "Bmr019.w.10,072", "text": "where we have both sides , so that we can try to answer this question of , you know , <vocalsound> is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard", "label": "qrr", "original_label": "qrr", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "48a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.27", "text": "A cursory analysis of background speech revealed that backchannels frequently occurred after a question was asked.", "type": "progress"}, "extractive": [{"id": "Bmr019.C.dialogueact992", "speaker": "C", "starttime": "2067.79", "startwordid": "Bmr019.w.9,312", "endtime": "2079.62", "endwordid": "Bmr019.w.9,360", "text": "When I was looking at these backchannels , they were turning up usually <disfmarker> <vocalsound> very often in <disfmarker> w well , I won't say \" usually \" <disfmarker> but anyway , very often , I picked them up in a channel <vocalsound> w which was the person who had asked a question .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "35a", "channel": "c2"}}]}, {"abstractive": {"id": "Bmr019.s.28", "text": "Backchannels also featured a high proportion of 'yeahs' and a substantially fewer 'uh-huhs'.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact1035", "speaker": "A", "starttime": "2135.44", "startwordid": "Bmr019.w.9,709", "endtime": "2137.87", "endwordid": "Bmr019.w.9,723", "text": "But there are fewer <disfmarker> I think there are fewer \" uh - huhs \" .", "label": "s^ng:s", "original_label": "s^ng:s", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "42b-2", "channel": "c0"}}, {"id": "Bmr019.A.dialogueact1044", "speaker": "A", "starttime": "2157.86", "startwordid": "Bmr019.w.9,812", "endtime": "2159.22", "endwordid": "Bmr019.w.9,820", "text": "And \" yeah \" is way up there ,", "label": "s:s", "original_label": "s:s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr019.s.29", "text": "Several group members are preparing Eurospeech submissions.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact1098", "speaker": "A", "starttime": "2253.14", "startwordid": "Bmr019.w.10,291", "endtime": "2255.26", "endwordid": "Bmr019.w.10,297", "text": "and I figured <vocalsound> we 'll try ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}, {"id": "Bmr019.B.dialogueact1484", "speaker": "B", "starttime": "2915.37", "startwordid": "Bmr019.w.13,518", "endtime": "2920.2", "endwordid": "Bmr019.w.13,536", "text": "Uh , you <disfmarker> you and , uh <disfmarker> and Dan have <disfmarker> have a paper that <disfmarker> that 's going in .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "52a", "channel": "c1"}}, {"id": "Bmr019.B.dialogueact1491", "speaker": "B", "starttime": "2925.78", "startwordid": "Bmr019.w.13,572", "endtime": "2929.34", "endwordid": "Bmr019.w.13,585", "text": "And the Aurora folks here will <disfmarker> will definitely get something in on Aurora ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr019.s.30", "text": "Speakers fe016 and mn017 are preparing a paper about the 'spurt' format, wherein spurts from individual channels---i.e. continuous speech regions delineated by pauses---will be extracted, merged with alignments from different channels, and time-aligned.", "type": "progress"}, "extractive": [{"id": "Bmr019.A.dialogueact1099", "speaker": "A", "starttime": "2255.26", "startwordid": "Bmr019.w.10,298", "endtime": "2261.63", "endwordid": "Bmr019.disfmarker.480", "text": "because that 'll at least get us to the point where we have <disfmarker> We have this really nice database format that Andreas and I were working out that <disfmarker>", "label": "s.%--", "original_label": "s.%--", "attributes": {"role": "PhD", "participant": "fe016", "channel": "c0"}}, {"id": "Bmr019.F.dialogueact1103", "speaker": "F", "starttime": "2266.7", "startwordid": "Bmr019.w.10,349", "endtime": "2268.88", "endwordid": "Bmr019.w.10,357", "text": "It 's the <disfmarker> it 's the spurt format .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "56b.57a", "channel": "c5"}}, {"id": "Bmr019.A.dialogueact1105", "speaker": "A", "starttime": "2270.96", "startwordid": "Bmr019.w.10,371", "endtime": "2275.47", "endwordid": "Bmr019.w.10,388", "text": "I was trying to find what 's a word for <pause> a continuous region with <pause> pauses around it ?", "label": "s^df", "original_label": "s^df", "attributes": {"role": "PhD", "participant": "fe016", "adjacency": "57b+.58a+", "channel": "c0"}}, {"id": "Bmr019.F.dialogueact1198", "speaker": "F", "starttime": "2411.43", "startwordid": "Bmr019.w.11,077", "endtime": "2414.93", "endwordid": "Bmr019.w.11,087", "text": "And then we merge all the alignments from the various channels", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact1199", "speaker": "F", "starttime": "2414.93", "startwordid": "Bmr019.w.11,088", "endtime": "2416.39", "endwordid": "Bmr019.w.11,094", "text": "and we sort them by time .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact1211", "speaker": "F", "starttime": "2457.23", "startwordid": "Bmr019.w.11,222", "endtime": "2462.6", "endwordid": "Bmr019.w.11,240", "text": "And so you extract the individual channels , uh , one sp spurt by spurt as it were .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}, {"id": "Bmr019.F.dialogueact1212", "speaker": "F", "starttime": "2463.17", "startwordid": "Bmr019.w.11,241", "endtime": "2468.76", "endwordid": "Bmr019.w.11,260", "text": "Um , and inside the words or between the words you now have begin and end <pause> tags for overlaps .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c5"}}]}]