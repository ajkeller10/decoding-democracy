[{"abstractive": {"id": "Bmr020.s.1", "text": "The main topics of the agenda were a paper submitted to Eurospeech and the organising of the recording transcriptions to be done by IBM.", "type": "abstract"}, "extractive": [{"id": "Bmr020.A.dialogueact79", "speaker": "A", "starttime": "112.351", "startwordid": "Bmr020.w.533", "endtime": "118.466", "endwordid": "Bmr020.w.557", "text": "so the only agenda items were Jane <disfmarker> was Jane wanted to talk about some of the IBM transcription process .", "label": "s^t", "original_label": "s^t", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "10a", "channel": "c0"}}, {"id": "Bmr020.F.dialogueact84", "speaker": "F", "starttime": "137.15", "startwordid": "Bmr020.w.619", "endtime": "140.996", "endwordid": "Bmr020.w.629", "text": "Uh , and you just sent off a Eurospeech paper ,", "label": "fg|s^bu", "original_label": "fg|s^bu", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "11a", "channel": "c5"}}, {"id": "Bmr020.F.dialogueact857", "speaker": "F", "starttime": "1429.0", "startwordid": "Bmr020.w.6,046", "endtime": "1432.19", "endwordid": "Bmr020.disfmarker.349", "text": "So , we should probably talk about the IBM transcription process stuff that <disfmarker>", "label": "s^cs^t^tc.%--", "original_label": "s^cs^t^tc.%--", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "35a", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr020.s.2", "text": "The results presented in the former show a significant percentage of overlapping speech even without counting in backchanneling.", "type": "abstract"}, "extractive": [{"id": "Bmr020.G.dialogueact204", "speaker": "G", "starttime": "274.615", "startwordid": "Bmr020.w.1,298", "endtime": "277.715", "endwordid": "Bmr020.w.1,310", "text": "Uh , the one was that the <disfmarker> just the <disfmarker> the amount of overlap", "label": "fh|s^e", "original_label": "fh|s^e", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact324", "speaker": "G", "starttime": "474.31", "startwordid": "Bmr020.w.2,225", "endtime": "476.37", "endwordid": "Bmr020.disfmarker.129", "text": "But , even if you take out all the backchannels <disfmarker>", "label": "s.%--", "original_label": "s.%--", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact329", "speaker": "G", "starttime": "480.87", "startwordid": "Bmr020.w.2,247", "endtime": "482.67", "endwordid": "Bmr020.w.2,252", "text": "you still have significant overlap .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.3", "text": "Additionally, the high error rate in the recognition of such overlapping speech by the SRI recogniser was minimised simply by changing the scoring method used.", "type": "abstract"}, "extractive": [{"id": "Bmr020.G.dialogueact342", "speaker": "G", "starttime": "516.223", "startwordid": "Bmr020.w.2,368", "endtime": "519.593", "endwordid": "Bmr020.w.2,379", "text": "And we rescored things um , a little bit more carefully .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact337", "speaker": "G", "starttime": "506.61", "startwordid": "Bmr020.w.2,331", "endtime": "515.385", "endwordid": "Bmr020.w.2,359", "text": "and then the second one was just basically the <disfmarker> <vocalsound> the stuff we had in the <disfmarker> in the HLT paper on how overlaps effect the <pause> recognition performance .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact373", "speaker": "G", "starttime": "608.931", "startwordid": "Bmr020.w.2,675", "endtime": "622.77", "endwordid": "Bmr020.w.2,717", "text": "But basically what we found is after we take out these regions <disfmarker> so we only score the regions that were certified as foreground speech , <comment> <vocalsound> the recognition error went down to almost <vocalsound> uh , the <pause> level of the non - overlapped <pause> speech .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "1a", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.4", "text": "Finally, a strong correlation between pauses and interruptions was confirmed.", "type": "abstract"}, "extractive": [{"id": "Bmr020.G.dialogueact529", "speaker": "G", "starttime": "967.15", "startwordid": "Bmr020.w.3,982", "endtime": "974.07", "endwordid": "Bmr020.w.4,008", "text": "so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted <vocalsound> than before .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.5", "text": "All these measurements were based on the sample of available transcripts.", "type": "abstract"}, "extractive": [{"id": "Bmr020.G.dialogueact173", "speaker": "G", "starttime": "239.52", "startwordid": "Bmr020.w.1,127", "endtime": "241.34", "endwordid": "Bmr020.w.1,135", "text": "No . Well , according to the transcripts .", "label": "s^ar|s", "original_label": "s^ar|s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "27b", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.6", "text": "Other features, like prosody, will be studied in the near future.", "type": "abstract"}, "extractive": [{"id": "Bmr020.G.dialogueact604", "speaker": "G", "starttime": "1066.77", "startwordid": "Bmr020.w.4,447", "endtime": "1070.66", "endwordid": "Bmr020.w.4,463", "text": "although that 's <disfmarker> I <disfmarker> I take it that 's something that uh Don will <disfmarker> will look at", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "29b++.30.5a", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.7", "text": "An FTP directory containing such experimental data is being set up for the benefit of other researchers.", "type": "abstract"}, "extractive": [{"id": "Bmr020.G.dialogueact702", "speaker": "G", "starttime": "1205.97", "startwordid": "Bmr020.w.5,075", "endtime": "1215.09", "endwordid": "Bmr020.w.5,111", "text": "and also , um , the other person that wants it <disfmarker> There is one person at SRI who wants to look at the <vocalsound> um , you know , the uh <disfmarker> the data we have so far ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "2a", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact704", "speaker": "G", "starttime": "1215.72", "startwordid": "Bmr020.w.5,114", "endtime": "1218.14", "endwordid": "Bmr020.w.5,124", "text": "and so I figured that FTP is the best <pause> approach .", "label": "s^df", "original_label": "s^df", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact705", "speaker": "G", "starttime": "1218.55", "startwordid": "Bmr020.w.5,125", "endtime": "1223.2", "endwordid": "Bmr020.w.5,139", "text": "So what I did is I um <disfmarker> <vocalsound> <vocalsound> @ @ <comment> I made a n new directory", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.8", "text": "Regarding the transcriptions to be carried out by IBM, the discussion mainly concerned the format of the recordings that should be sent to them.", "type": "abstract"}, "extractive": [{"id": "Bmr020.A.dialogueact79", "speaker": "A", "starttime": "112.351", "startwordid": "Bmr020.w.533", "endtime": "118.466", "endwordid": "Bmr020.w.557", "text": "so the only agenda items were Jane <disfmarker> was Jane wanted to talk about some of the IBM transcription process .", "label": "s^t", "original_label": "s^t", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "10a", "channel": "c0"}}, {"id": "Bmr020.F.dialogueact857", "speaker": "F", "starttime": "1429.0", "startwordid": "Bmr020.w.6,046", "endtime": "1432.19", "endwordid": "Bmr020.disfmarker.349", "text": "So , we should probably talk about the IBM transcription process stuff that <disfmarker>", "label": "s^cs^t^tc.%--", "original_label": "s^cs^t^tc.%--", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "35a", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr020.s.9", "text": "Suggestions included sending only the channels with the dominant speakers for transcription, but it was finally agreed on sending the original files with minimal modifications, as there will be extensive in-house post-processing.", "type": "abstract"}, "extractive": [{"id": "Bmr020.C.dialogueact1157", "speaker": "C", "starttime": "2114.27", "startwordid": "Bmr020.w.8,849", "endtime": "2124.76", "endwordid": "Bmr020.w.8,882", "text": "And , if the chunked files focused on the dominant speakers , <vocalsound> then , when <disfmarker> when it got s patched together when it comes back from IBM , we can add the backchannels .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c2"}}, {"id": "Bmr020.B.dialogueact1244", "speaker": "B", "starttime": "2335.93", "startwordid": "Bmr020.w.9,776", "endtime": "2341.78", "endwordid": "Bmr020.w.9,795", "text": "and you just use the s the segments of the dominant speaker then ? For <disfmarker> for sending to <disfmarker> to IBM", "label": "qy^d^rt", "original_label": "qy^d^rt", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "27a", "channel": "c1"}}, {"id": "Bmr020.B.dialogueact1287", "speaker": "B", "starttime": "2433.62", "startwordid": "Bmr020.w.10,243", "endtime": "2439.81", "endwordid": "Bmr020.w.10,268", "text": "But then we could just use the <disfmarker> the output of the detector , and do the beeping on it , and send it to I B", "label": "s^cs^ng", "original_label": "s^cs^ng", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "2b.3a", "channel": "c1"}}, {"id": "Bmr020.D.dialogueact1288", "speaker": "D", "starttime": "2440.8", "startwordid": "Bmr020.w.10,271", "endtime": "2441.96", "endwordid": "Bmr020.w.10,276", "text": "Without having her check anything .", "label": "s^2", "original_label": "s^2", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "3b.4a", "channel": "c3"}}, {"id": "Bmr020.F.dialogueact1444", "speaker": "F", "starttime": "2616.42", "startwordid": "Bmr020.w.11,326", "endtime": "2627.75", "endwordid": "Bmr020.w.11,373", "text": "but <disfmarker> but I <disfmarker> I <disfmarker> I have <pause> another suggestion on that , which is , <vocalsound> since , really what this is , is <disfmarker> is <disfmarker> is trying to in the large , send the right thing to them and there is gonna be this <disfmarker> this post - processing step ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c5"}}, {"id": "Bmr020.F.dialogueact1462", "speaker": "F", "starttime": "2653.25", "startwordid": "Bmr020.w.11,508", "endtime": "2654.71", "endwordid": "Bmr020.w.11,515", "text": "and we 'll <disfmarker> we 'll fix things up", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr020.s.10", "text": "Within this discussion, the rationale behind the coding of the time bins according to the flow of discourse was also explained.", "type": "abstract"}, "extractive": [{"id": "Bmr020.C.dialogueact1026", "speaker": "C", "starttime": "1742.56", "startwordid": "Bmr020.w.7,454", "endtime": "1750.15", "endwordid": "Bmr020.w.7,485", "text": "so that if you <disfmarker> if you play <pause> back that bin and have it in the mode where it stops at the boundary , <vocalsound> it sounds like a normal word .", "label": "s^e", "original_label": "s^e", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "68b+", "channel": "c2"}}, {"id": "Bmr020.C.dialogueact1061", "speaker": "C", "starttime": "1845.02", "startwordid": "Bmr020.w.7,856", "endtime": "1854.31", "endwordid": "Bmr020.w.7,881", "text": "but my general goal <vocalsound> when there was <pause> sufficient space , room , pause <pause> after it <pause> to have it be <pause> kind of a natural feeling <pause> gap .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c2"}}]}, {"abstractive": {"id": "Bmr020.s.11", "text": "The files made available in the FTP directory will be the original ones (before down-sampling), as these seem to be wanted by other parties.", "type": "decisions"}, "extractive": [{"id": "Bmr020.G.dialogueact816", "speaker": "G", "starttime": "1379.92", "startwordid": "Bmr020.w.5,813", "endtime": "1383.38", "endwordid": "Bmr020.w.5,824", "text": "we should probably <disfmarker> uh <pause> give them the non - downsampled versions .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "26a", "channel": "ca"}}, {"id": "Bmr020.E.dialogueact842", "speaker": "E", "starttime": "1414.15", "startwordid": "Bmr020.w.5,975", "endtime": "1416.63", "endwordid": "Bmr020.w.5,984", "text": "But , um <pause> they probably w want the originals .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me001", "adjacency": "32b+++", "channel": "c4"}}]}, {"abstractive": {"id": "Bmr020.s.12", "text": "Moreover, as files may have been modified through different processing, tests will be carried out in order to ensure the generation of beep files in a consistent way.", "type": "decisions"}, "extractive": [{"id": "Bmr020.D.dialogueact901", "speaker": "D", "starttime": "1511.61", "startwordid": "Bmr020.w.6,429", "endtime": "1525.89", "endwordid": "Bmr020.w.6,481", "text": "Yeah , in fact after our meeting uh , this morning Thilo came in and said that <vocalsound> um , there could be <pause> other differences between <vocalsound> the uh <pause> already transcribed meeting with the beeps in it and one that has <pause> just r been run through his process .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact904", "speaker": "D", "starttime": "1525.89", "startwordid": "Bmr020.w.6,482", "endtime": "1533.2", "endwordid": "Bmr020.w.6,511", "text": "So tomorrow , <vocalsound> when we go to make the um <pause> uh , chunked file <vocalsound> for IBM , we 're going to actually compare the two .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "42a", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact907", "speaker": "D", "starttime": "1536.41", "startwordid": "Bmr020.w.6,527", "endtime": "1541.75", "endwordid": "Bmr020.w.6,552", "text": "and then we 're gonna do the beep - ify on both , and listen to them and see if we notice any real differences .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "43a", "channel": "c3"}}]}, {"abstractive": {"id": "Bmr020.s.13", "text": "Also towards this goal, some of the time bins will need to be merged.", "type": "decisions"}, "extractive": [{"id": "Bmr020.A.dialogueact886", "speaker": "A", "starttime": "1489.23", "startwordid": "Bmr020.w.6,313", "endtime": "1497.26", "endwordid": "Bmr020.w.6,347", "text": "So what <disfmarker> what we 're probably gonna do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c0"}}, {"id": "Bmr020.C.dialogueact1110", "speaker": "C", "starttime": "1978.81", "startwordid": "Bmr020.w.8,302", "endtime": "1985.85", "endwordid": "Bmr020.w.8,329", "text": "But I like this idea of <disfmarker> uh , for our purposes for the <disfmarker> for the IBM preparation , <vocalsound> uh , n having these <pause> joined together ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c2"}}]}, {"abstractive": {"id": "Bmr020.s.14", "text": "On the other hand, the two meetings where time bins have been hand-coded in detail will be used to fine-tune the forced alignments.", "type": "decisions"}, "extractive": [{"id": "Bmr020.G.dialogueact972", "speaker": "G", "starttime": "1650.3", "startwordid": "Bmr020.w.7,052", "endtime": "1654.6", "endwordid": "Bmr020.w.7,064", "text": "Uh , because we could use that to fine tune our alignment process", "label": "s^df", "original_label": "s^df", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact969", "speaker": "G", "starttime": "1638.64", "startwordid": "Bmr020.w.7,014", "endtime": "1647.33", "endwordid": "Bmr020.w.7,039", "text": "I mean w I mean what I would <disfmarker> I was interested in is having <disfmarker> <vocalsound> a se having time marks for the beginnings and ends of speech", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "57a", "channel": "ca"}}, {"id": "Bmr020.C.dialogueact1093", "speaker": "C", "starttime": "1937.95", "startwordid": "Bmr020.w.8,164", "endtime": "1939.56", "endwordid": "Bmr020.w.8,171", "text": "I <disfmarker> I hand - adjusted two of them", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "4a+", "channel": "c2"}}, {"id": "Bmr020.G.dialogueact1098", "speaker": "G", "starttime": "1941.68", "startwordid": "Bmr020.w.8,190", "endtime": "1945.92", "endwordid": "Bmr020.w.8,204", "text": "So <disfmarker> so at some point we will try to fine - tune our forced alignment", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "5a", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.15", "text": "Recordings will be sent to IBM for transcription.", "type": "decisions"}, "extractive": [{"id": "Bmr020.D.dialogueact780", "speaker": "D", "starttime": "1343.27", "startwordid": "Bmr020.w.5,620", "endtime": "1345.16", "endwordid": "Bmr020.w.5,628", "text": "We need to give Brian the beeps file ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "14a", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact1334", "speaker": "D", "starttime": "2500.07", "startwordid": "Bmr020.w.10,597", "endtime": "2500.84", "endwordid": "Bmr020.w.10,603", "text": "and we send it to IBM .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "me018", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact1336", "speaker": "D", "starttime": "2500.84", "startwordid": "Bmr020.w.10,604", "endtime": "2503.32", "endwordid": "Bmr020.w.10,622", "text": "The other one is <vocalsound> we just run his thing and send it to IBM .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "me018", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact1660", "speaker": "D", "starttime": "2995.92", "startwordid": "Bmr020.w.13,078", "endtime": "2996.91", "endwordid": "Bmr020.w.13,083", "text": "send it off to IBM .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "64a+++", "channel": "c3"}}]}, {"abstractive": {"id": "Bmr020.s.16", "text": "Before that, the files will be automatically pre-segmented into speech/non-speech bins and the beeps will be inserted.", "type": "decisions"}, "extractive": [{"id": "Bmr020.B.dialogueact1287", "speaker": "B", "starttime": "2433.62", "startwordid": "Bmr020.w.10,243", "endtime": "2439.81", "endwordid": "Bmr020.w.10,268", "text": "But then we could just use the <disfmarker> the output of the detector , and do the beeping on it , and send it to I B", "label": "s^cs^ng", "original_label": "s^cs^ng", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "2b.3a", "channel": "c1"}}, {"id": "Bmr020.D.dialogueact1331", "speaker": "D", "starttime": "2494.88", "startwordid": "Bmr020.w.10,559", "endtime": "2498.09", "endwordid": "Bmr020.w.10,584", "text": "So the <disfmarker> the one suggestion is you know we <disfmarker> <vocalsound> we run Thilo 's thing", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "13a", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact1336", "speaker": "D", "starttime": "2500.84", "startwordid": "Bmr020.w.10,604", "endtime": "2503.32", "endwordid": "Bmr020.w.10,622", "text": "The other one is <vocalsound> we just run his thing and send it to IBM .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "me018", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact1340", "speaker": "D", "starttime": "2507.9", "startwordid": "Bmr020.w.10,638", "endtime": "2514.36", "endwordid": "Bmr020.w.10,671", "text": "and that is <vocalsound> if we go ahead and we <vocalsound> just run his , and we generate the beeps file , then we have somebody listen beeps file .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "PhD", "participant": "me018", "channel": "c3"}}, {"id": "Bmr020.D.dialogueact1659", "speaker": "D", "starttime": "2995.25", "startwordid": "Bmr020.w.13,073", "endtime": "2995.92", "endwordid": "Bmr020.w.13,077", "text": "put the beeps file ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "64a++", "channel": "c3"}}]}, {"abstractive": {"id": "Bmr020.s.17", "text": "In order to make things easier for the transcribers, breathy channels, which are erroneously marked as speech, will be re-classified correctly with other methods.", "type": "decisions"}, "extractive": [{"id": "Bmr020.C.dialogueact1581", "speaker": "C", "starttime": "2862.97", "startwordid": "Bmr020.w.12,404", "endtime": "2870.35", "endwordid": "Bmr020.w.12,435", "text": "The other problem is , that when it <disfmarker> when it uh d i on the breathy ones , where you get <vocalsound> <vocalsound> breathing , uh , inti indicated as speech .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c2"}}, {"id": "Bmr020.B.dialogueact1620", "speaker": "B", "starttime": "2949.82", "startwordid": "Bmr020.w.12,802", "endtime": "2952.56", "endwordid": "Bmr020.w.12,812", "text": "So , I could run this on those breathy channels ,", "label": "s^cs^rt", "original_label": "s^cs^rt", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "59a++", "channel": "c1"}}, {"id": "Bmr020.F.dialogueact1626", "speaker": "F", "starttime": "2958.04", "startwordid": "Bmr020.w.12,851", "endtime": "2959.94", "endwordid": "Bmr020.w.12,864", "text": "and what that 'll do is just cut the time a little further .", "label": "s^na", "original_label": "s^na", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "59b-3++.60a", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr020.s.18", "text": "All this pre-processing will have to be evaluated first by checking a sample of the output files.", "type": "decisions"}, "extractive": [{"id": "Bmr020.F.dialogueact1446", "speaker": "F", "starttime": "2629.67", "startwordid": "Bmr020.w.11,376", "endtime": "2632.62", "endwordid": "Bmr020.w.11,388", "text": "why don't we check through a bunch of things by sampling it ?", "label": "qh^cs", "original_label": "qh^cs", "attributes": {"role": "Professor", "participant": "me013", "channel": "c5"}}]}, {"abstractive": {"id": "Bmr020.s.19", "text": "Other issues, like whether and how synthesised speech off a laptop needs be transcribed, will be resolved during the in-house post-processing of the transcriptions.", "type": "decisions"}, "extractive": [{"id": "Bmr020.A.dialogueact1701", "speaker": "A", "starttime": "3041.9", "startwordid": "Bmr020.w.13,303", "endtime": "3042.5", "endwordid": "Bmr020.w.13,307", "text": "What can you do ?", "label": "qw", "original_label": "qw", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "6b", "channel": "c0"}}, {"id": "Bmr020.A.dialogueact1805", "speaker": "A", "starttime": "3172.19", "startwordid": "Bmr020.w.14,000", "endtime": "3173.71", "endwordid": "Bmr020.w.14,009", "text": "and we 'll correct it when it comes back .", "label": "s^co^e", "original_label": "s^co^e", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "30b-1++++", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr020.s.20", "text": "There is a slight worry about the acceptance of the paper submitted to Eurospeech as the deadline was exceeded.", "type": "problems"}, "extractive": [{"id": "Bmr020.G.dialogueact98", "speaker": "G", "starttime": "153.957", "startwordid": "Bmr020.w.692", "endtime": "157.177", "endwordid": "Bmr020.w.702", "text": "We actually exceeded the delayed deadline by o another day ,", "label": "s^na", "original_label": "s^na", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "12b.13a", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact87", "speaker": "G", "starttime": "143.11", "startwordid": "Bmr020.w.634", "endtime": "144.13", "endwordid": "Bmr020.w.639", "text": "I hope they accept it .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.21", "text": "As to the content of the paper, the overlap statistics have not been normalised against the number of participants in the conversation, although the dependency is probably going to be a weak one.", "type": "problems"}, "extractive": [{"id": "Bmr020.G.dialogueact292", "speaker": "G", "starttime": "444.809", "startwordid": "Bmr020.w.2,038", "endtime": "446.269", "endwordid": "Bmr020.w.2,047", "text": "Well , we didn't get to look at that ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.D.dialogueact289", "speaker": "D", "starttime": "442.61", "startwordid": "Bmr020.w.2,005", "endtime": "445.0", "endwordid": "Bmr020.w.2,022", "text": "Yeah , I just wonder if you have to normalize by the numbers of speakers or something .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "adjacency": "44a", "channel": "c3"}}, {"id": "Bmr020.A.dialogueact300", "speaker": "A", "starttime": "451.657", "startwordid": "Bmr020.w.2,082", "endtime": "453.037", "endwordid": "Bmr020.w.2,089", "text": "I bet there 's a weak dependence .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "45a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr020.s.22", "text": "Additionally, the correlation between pauses in speech and interruptions does not provide a cause-and-effect link for these phenomena.", "type": "problems"}, "extractive": [{"id": "Bmr020.G.dialogueact546", "speaker": "G", "starttime": "1000.0", "startwordid": "Bmr020.w.4,118", "endtime": "1001.74", "endwordid": "Bmr020.w.4,126", "text": "There 's no statement about cause and effect .", "label": "s^ng", "original_label": "s^ng", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "22b+", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.23", "text": "The preparation of files for transcription by IBM is facing some minor difficulties, as some features (hand-coded time boundaries, multiplicity of channels etc) may complicate the generation of beep files.", "type": "problems"}, "extractive": [{"id": "Bmr020.D.dialogueact901", "speaker": "D", "starttime": "1511.61", "startwordid": "Bmr020.w.6,429", "endtime": "1525.89", "endwordid": "Bmr020.w.6,481", "text": "Yeah , in fact after our meeting uh , this morning Thilo came in and said that <vocalsound> um , there could be <pause> other differences between <vocalsound> the uh <pause> already transcribed meeting with the beeps in it and one that has <pause> just r been run through his process .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "me018", "channel": "c3"}}, {"id": "Bmr020.A.dialogueact937", "speaker": "A", "starttime": "1595.05", "startwordid": "Bmr020.w.6,814", "endtime": "1596.26", "endwordid": "Bmr020.w.6,820", "text": "That 's because of channel overlap .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "51b+", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr020.s.24", "text": "Besides this, the automatic pre-segmentation has been deemed to be good, but there are still no specific measurements to verify this.", "type": "problems"}, "extractive": [{"id": "Bmr020.C.dialogueact1269", "speaker": "C", "starttime": "2388.22", "startwordid": "Bmr020.w.10,024", "endtime": "2396.92", "endwordid": "Bmr020.w.10,066", "text": "But you know , I wanted to say , his segmentation is so good , that <vocalsound> um , the part that I listened to with her yesterday <vocalsound> didn't need any adjustments of the bins .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "30a", "channel": "c2"}}, {"id": "Bmr020.B.dialogueact1564", "speaker": "B", "starttime": "2819.85", "startwordid": "Bmr020.w.12,263", "endtime": "2826.11", "endwordid": "Bmr020.w.12,279", "text": "I can't <comment> really <disfmarker> hhh , <comment> <pause> Tsk . <comment> I <pause> don't have really representative numbers , I think .", "label": "s^no", "original_label": "s^no", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "51b", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr020.s.25", "text": "The pre-segmentation tool also classifies synthesised speech used in a recording as \"normal speech\" and assigns a random channel to it.", "type": "problems"}, "extractive": [{"id": "Bmr020.B.dialogueact1698", "speaker": "B", "starttime": "3033.18", "startwordid": "Bmr020.w.13,270", "endtime": "3039.53", "endwordid": "Bmr020.w.13,288", "text": "And i <vocalsound> the speech - nonspeech detector just assigns randomly the speech to <disfmarker> to one of the channels ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "6a", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr020.s.26", "text": "The transcribers at IBM may not be able to differentiate between the two.", "type": "problems"}, "extractive": [{"id": "Bmr020.A.dialogueact1720", "speaker": "A", "starttime": "3066.93", "startwordid": "Bmr020.w.13,409", "endtime": "3068.93", "endwordid": "Bmr020.w.13,418", "text": "a hand - transcriber would have trouble with that .", "label": "s^bsc^df", "original_label": "s^bsc^df", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "9b-2+++.10a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr020.s.27", "text": "A paper has been submitted to Eurospeech, which also includes a section on new corpora.", "type": "progress"}, "extractive": [{"id": "Bmr020.F.dialogueact84", "speaker": "F", "starttime": "137.15", "startwordid": "Bmr020.w.619", "endtime": "140.996", "endwordid": "Bmr020.w.629", "text": "Uh , and you just sent off a Eurospeech paper ,", "label": "fg|s^bu", "original_label": "fg|s^bu", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "11a", "channel": "c5"}}, {"id": "Bmr020.A.dialogueact111", "speaker": "A", "starttime": "173.49", "startwordid": "Bmr020.w.778", "endtime": "184.322", "endwordid": "Bmr020.w.815", "text": "uh , Dave Gelbart sent me email , I think he sent it to you too , <comment> that um , there 's a special topic , section in si in Eurospeech on new , corp corpors corpora .", "label": "fg|s", "original_label": "fg|s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "16a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr020.s.28", "text": "The statistics in the paper are based on the transcripts of two meeting and two telephone conversation corpora.", "type": "progress"}, "extractive": [{"id": "Bmr020.G.dialogueact173", "speaker": "G", "starttime": "239.52", "startwordid": "Bmr020.w.1,127", "endtime": "241.34", "endwordid": "Bmr020.w.1,135", "text": "No . Well , according to the transcripts .", "label": "s^ar|s", "original_label": "s^ar|s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "27b", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact210", "speaker": "G", "starttime": "289.52", "startwordid": "Bmr020.w.1,361", "endtime": "300.74", "endwordid": "Bmr020.w.1,388", "text": "Um , and we computed how many overlapped i uh spurts there were and how many overlapped words there were . <vocalsound> Um , for four different <pause> corpora ,", "label": "fh|s", "original_label": "fh|s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "32b+++++", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.29", "text": "In the first two, the overlapped words vary between 9% and 18%.", "type": "progress"}, "extractive": [{"id": "Bmr020.G.dialogueact204", "speaker": "G", "starttime": "274.615", "startwordid": "Bmr020.w.1,298", "endtime": "277.715", "endwordid": "Bmr020.w.1,310", "text": "Uh , the one was that the <disfmarker> just the <disfmarker> the amount of overlap", "label": "fh|s^e", "original_label": "fh|s^e", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact207", "speaker": "G", "starttime": "278.745", "startwordid": "Bmr020.w.1,323", "endtime": "280.715", "endwordid": "Bmr020.w.1,332", "text": "s in terms of <disfmarker> in terms of number of words", "label": "s^e", "original_label": "s^e", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "32b++", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact282", "speaker": "G", "starttime": "423.58", "startwordid": "Bmr020.w.1,922", "endtime": "432.603", "endwordid": "Bmr020.w.1,958", "text": "So , <vocalsound> in terms of number of words , it 's like seventeen or eigh eighteen percent for the Meeting Recorder meetings and <vocalsound> about half that for , <vocalsound> uh , the Robustness .", "label": "fh|s", "original_label": "fh|s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "41b++.43a", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.30", "text": "The telephone conversation results were in-between and very similar to each other.", "type": "progress"}, "extractive": [{"id": "Bmr020.G.dialogueact220", "speaker": "G", "starttime": "320.731", "startwordid": "Bmr020.w.1,435", "endtime": "323.081", "endwordid": "Bmr020.w.1,443", "text": "uh , but next were Switchboard and CallHome ,", "label": "fh|s", "original_label": "fh|s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "32b+++++++++++++", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact221", "speaker": "G", "starttime": "323.161", "startwordid": "Bmr020.w.1,444", "endtime": "324.621", "endwordid": "Bmr020.w.1,450", "text": "which both had roughly the same ,", "label": "s^e", "original_label": "s^e", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "32b++++++++++++++", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.31", "text": "On the other hand, the automatic recognition errors affected by overlaps were reduced dramatically by focusing on regions with the foreground speech.", "type": "progress"}, "extractive": [{"id": "Bmr020.G.dialogueact337", "speaker": "G", "starttime": "506.61", "startwordid": "Bmr020.w.2,331", "endtime": "515.385", "endwordid": "Bmr020.w.2,359", "text": "and then the second one was just basically the <disfmarker> <vocalsound> the stuff we had in the <disfmarker> in the HLT paper on how overlaps effect the <pause> recognition performance .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact373", "speaker": "G", "starttime": "608.931", "startwordid": "Bmr020.w.2,675", "endtime": "622.77", "endwordid": "Bmr020.w.2,717", "text": "But basically what we found is after we take out these regions <disfmarker> so we only score the regions that were certified as foreground speech , <comment> <vocalsound> the recognition error went down to almost <vocalsound> uh , the <pause> level of the non - overlapped <pause> speech .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "1a", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.32", "text": "Furthermore, it was shown that after spurts, backchannels, disfluencies and discourse markers, the likelihood of interruption by other speakers was much higher.", "type": "progress"}, "extractive": [{"id": "Bmr020.G.dialogueact500", "speaker": "G", "starttime": "873.32", "startwordid": "Bmr020.w.3,667", "endtime": "873.91", "endwordid": "Bmr020.w.3,670", "text": "End of spurt .", "label": "s^bsc", "original_label": "s^bsc", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact503", "speaker": "G", "starttime": "882.54", "startwordid": "Bmr020.w.3,697", "endtime": "884.72", "endwordid": "Bmr020.w.3,705", "text": "and then we had things like discourse markers ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact504", "speaker": "G", "starttime": "885.71", "startwordid": "Bmr020.w.3,706", "endtime": "886.97", "endwordid": "Bmr020.w.3,709", "text": "uh , backchannels ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact505", "speaker": "G", "starttime": "888.08", "startwordid": "Bmr020.w.3,710", "endtime": "889.2", "endwordid": "Bmr020.w.3,713", "text": "uh , disfluencies .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact529", "speaker": "G", "starttime": "967.15", "startwordid": "Bmr020.w.3,982", "endtime": "974.07", "endwordid": "Bmr020.w.4,008", "text": "so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted <vocalsound> than before .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact531", "speaker": "G", "starttime": "975.43", "startwordid": "Bmr020.w.4,011", "endtime": "977.41", "endwordid": "Bmr020.w.4,018", "text": "And also of course after spurt ends ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.33", "text": "Files with the recordings, as well as some experimental data will be available for other researchers in an FTP directory that is being set up.", "type": "progress"}, "extractive": [{"id": "Bmr020.G.dialogueact702", "speaker": "G", "starttime": "1205.97", "startwordid": "Bmr020.w.5,075", "endtime": "1215.09", "endwordid": "Bmr020.w.5,111", "text": "and also , um , the other person that wants it <disfmarker> There is one person at SRI who wants to look at the <vocalsound> um , you know , the uh <disfmarker> the data we have so far ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "2a", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact704", "speaker": "G", "starttime": "1215.72", "startwordid": "Bmr020.w.5,114", "endtime": "1218.14", "endwordid": "Bmr020.w.5,124", "text": "and so I figured that FTP is the best <pause> approach .", "label": "s^df", "original_label": "s^df", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact705", "speaker": "G", "starttime": "1218.55", "startwordid": "Bmr020.w.5,125", "endtime": "1223.2", "endwordid": "Bmr020.w.5,139", "text": "So what I did is I um <disfmarker> <vocalsound> <vocalsound> @ @ <comment> I made a n new directory", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}, {"id": "Bmr020.G.dialogueact747", "speaker": "G", "starttime": "1288.34", "startwordid": "Bmr020.w.5,385", "endtime": "1294.83", "endwordid": "Bmr020.w.5,409", "text": "So all I <disfmarker> all I was gonna do there was stick the <disfmarker> the transcripts after we <disfmarker> the way that we munged them for scoring ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "ca"}}]}, {"abstractive": {"id": "Bmr020.s.34", "text": "Parts of the recordings will have to be beeped out by a script that has already been developed.", "type": "progress"}, "extractive": [{"id": "Bmr020.C.dialogueact860", "speaker": "C", "starttime": "1434.01", "startwordid": "Bmr020.w.6,063", "endtime": "1438.85", "endwordid": "Bmr020.w.6,082", "text": "So , um you know that Adam created um , a b a script to generate the beep file ?", "label": "h|qy^d^rt", "original_label": "h|qy^d^rt", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "35b+", "channel": "c2"}}]}, {"abstractive": {"id": "Bmr020.s.35", "text": "Finally, EDU meetings already recorded have now been pre-segmented and assigned to the transcribers at ICSI.", "type": "progress"}, "extractive": [{"id": "Bmr020.C.dialogueact1140", "speaker": "C", "starttime": "2032.08", "startwordid": "Bmr020.w.8,555", "endtime": "2038.44", "endwordid": "Bmr020.w.8,579", "text": "so the e EDU meetings , that <vocalsound> Thilo ha has now presegmented all of them for us , on a channel by channel basis .", "label": "s^e", "original_label": "s^e", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c2"}}, {"id": "Bmr020.C.dialogueact1142", "speaker": "C", "starttime": "2040.04", "startwordid": "Bmr020.w.8,583", "endtime": "2044.53", "endwordid": "Bmr020.w.8,596", "text": "so , I 've assigned <disfmarker> I 've <disfmarker> I 've assigned them to our transcribers", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c2"}}]}]