[{"id": "Bmr019.s.1", "text": "The Berkeley Meeting Recorder group discussed efforts to train and test the Aurora group's HTK-based recognition system on ICSI's digits corpus.", "type": "abstract"}, {"id": "Bmr019.s.2", "text": "Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data.", "type": "abstract"}, {"id": "Bmr019.s.3", "text": "Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers.", "type": "abstract"}, {"id": "Bmr019.s.4", "text": "While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work.", "type": "abstract"}, {"id": "Bmr019.s.5", "text": "The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly.", "type": "abstract"}, {"id": "Bmr019.s.6", "text": "For comparing Meeting Recorder digits results, it was decided that the Aurora HTK-based system should be tested on data from the TI digits corpus.", "type": "decisions"}, {"id": "Bmr019.s.7", "text": "The script for extracting speaker ID information will require modifications to obtain a more accurate estimation of the amount of data recorded per speaker.", "type": "decisions"}, {"id": "Bmr019.s.8", "text": "Subsequent recognition experiments will look at large vocabulary speech from a far-field microphone (as performed in Switchboard evaluations).", "type": "decisions"}, {"id": "Bmr019.s.9", "text": "Hand-marked, word-level alignments are needed to reveal speaker boundaries and tune the parameters of the model.", "type": "decisions"}, {"id": "Bmr019.s.10", "text": "Modifications to the Transcriber tool are required for allowing transcribers to simultaneously view the signal in XWaves and see where words are located in time.", "type": "decisions"}, {"id": "Bmr019.s.11", "text": "Digits training needs to be performed on a larger data set.", "type": "problems"}, {"id": "Bmr019.s.12", "text": "A significant loss in recognition resulted from not having included the type of phone-loop adaptation found in the SRI system.", "type": "problems"}, {"id": "Bmr019.s.13", "text": "Recognition performance was worse for digits recorded in closed microphone conditions versus those recorded in a studio (e.g. TI-digits).", "type": "problems"}, {"id": "Bmr019.s.14", "text": "A mismatch between the manner in which data were collected and the models used for doing recognition---e.g. bandwidth parameterization and the use of near- versus far-field microphones---was identified.", "type": "problems"}, {"id": "Bmr019.s.15", "text": "Too little data per speaker can have a negative effect on VTL estimation.", "type": "problems"}, {"id": "Bmr019.s.16", "text": "The PZM channel selected for obtaining digits data was too far away from most of the speakers.", "type": "problems"}, {"id": "Bmr019.s.17", "text": "Current speech alignment techniques assume that foreground speech must be continuous and, barring some isolated words and backchannels, can not cope with overlapping background speech.", "type": "problems"}, {"id": "Bmr019.s.18", "text": "Performing adaptations on both the foreground and background speaker produced a new variety of misalignments, a problem resulting, in part, from the fact that background speakers often match better to foreground conditionss.", "type": "problems"}, {"id": "Bmr019.s.19", "text": "Transcribers occasionally misidentified speakers and omitted backchannels that were more hidden in the mixed signal.", "type": "problems"}, {"id": "Bmr019.s.20", "text": "Good recognition performance was achieved with the lapel microphones.", "type": "progress"}, {"id": "Bmr019.s.21", "text": "The recognizer performed well on time-aligned segments labelled as 'non-overlap' (i.e. one person talking), while segments labelled as 'overlap' (i.e. multiple speakers talking at the same time) yielded poor results.", "type": "progress"}, {"id": "Bmr019.s.22", "text": "Future recognition efforts will include looking at reverberation.", "type": "progress"}, {"id": "Bmr019.s.23", "text": "Forced alignment improvements were gained by examining the types of errors generated and making the necessary adjustments.", "type": "progress"}, {"id": "Bmr019.s.24", "text": "More accurate alignments were achieved by significantly increasing the pruning value.", "type": "progress"}, {"id": "Bmr019.s.25", "text": "Future alignment efforts will include cloning the reject model, and adapting it to both the foreground and background speaker.", "type": "progress"}, {"id": "Bmr019.s.26", "text": "Members of the group will also compare Meeting Recorder data with other corpora (e.g. Switchboard) to determine whether speaker overlap is a feature that is more specific to meetings versus other modes of spoken interaction.", "type": "progress"}, {"id": "Bmr019.s.27", "text": "A cursory analysis of background speech revealed that backchannels frequently occurred after a question was asked.", "type": "progress"}, {"id": "Bmr019.s.28", "text": "Backchannels also featured a high proportion of 'yeahs' and a substantially fewer 'uh-huhs'.", "type": "progress"}, {"id": "Bmr019.s.29", "text": "Several group members are preparing Eurospeech submissions.", "type": "progress"}, {"id": "Bmr019.s.30", "text": "Speakers fe016 and mn017 are preparing a paper about the 'spurt' format, wherein spurts from individual channels---i.e. continuous speech regions delineated by pauses---will be extracted, merged with alignments from different channels, and time-aligned.", "type": "progress"}]