[{"abstractive": {"id": "Bmr010.s.1", "text": "The Berkeley Meeting Recorder group talked about the ongoing transcription effort and issues related to the Transcriber tool, which despite its limitations for capturing tight time markings for overlapping speech, will continue to remain in use.", "type": "abstract"}, "extractive": [{"id": "Bmr010.F.dialogueact28", "speaker": "F", "starttime": "37.968", "startwordid": "Bmr010.w.165", "endtime": "41.128", "endwordid": "Bmr010.w.179", "text": "Well , um , I can <pause> give you an update on the <pause> transcription effort .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "6a", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact239", "speaker": "F", "starttime": "467.798", "startwordid": "Bmr010.w.1,862", "endtime": "472.7", "endwordid": "Bmr010.w.1,879", "text": "because at present , <nonvocalsound> <vocalsound> um , because <nonvocalsound> of the limitations of <vocalsound> th the interface we 're using ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact240", "speaker": "F", "starttime": "472.98", "startwordid": "Bmr010.w.1,880", "endtime": "482.086", "endwordid": "Bmr010.w.1,905", "text": "overlaps are , uh , not being <nonvocalsound> encoded by <nonvocalsound> the transcribers in as complete <nonvocalsound> and , uh , detailed a way as it might be ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.A.dialogueact322", "speaker": "A", "starttime": "659.925", "startwordid": "Bmr010.w.2,691", "endtime": "666.275", "endwordid": "Bmr010.w.2,715", "text": "What our decision was is that <pause> we 'll go ahead with what we have with a not very fine time scale on the overlaps .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "7a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.2", "text": "Speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions.", "type": "abstract"}, "extractive": [{"id": "Bmr010.F.dialogueact34", "speaker": "F", "starttime": "57.342", "startwordid": "Bmr010.w.224", "endtime": "62.932", "endwordid": "Bmr010.w.248", "text": "The <disfmarker> we have great <disfmarker> great , uh , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "7a", "channel": "c8"}}, {"id": "Bmr010.C.dialogueact122", "speaker": "C", "starttime": "245.001", "startwordid": "Bmr010.w.957", "endtime": "255.361", "endwordid": "Bmr010.w.984", "text": "Um , so , uh , what we basically did so far was using the mixed file to <disfmarker> to detect s speech or nonspeech <pause> portions in that .", "label": "h|s^rt", "original_label": "h|s^rt", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}, {"id": "Bmr010.F.dialogueact203", "speaker": "F", "starttime": "414.922", "startwordid": "Bmr010.w.1,587", "endtime": "417.012", "endwordid": "Bmr010.w.1,596", "text": "But <nonvocalsound> it <disfmarker> it saves so much time <disfmarker> the <disfmarker> the <nonvocalsound> transcribers", "label": "s^arp", "original_label": "s^arp", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "32b-2+.33a", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr010.s.3", "text": "Recording equipment and procedures were discussed, with a focus on audible breathing and the need for standards in microphone wear and use.", "type": "abstract"}, "extractive": [{"id": "Bmr010.F.dialogueact30", "speaker": "F", "starttime": "42.04", "startwordid": "Bmr010.w.182", "endtime": "47.13", "endwordid": "Bmr010.w.194", "text": "Uh , maybe <nonvocalsound> raise the issue of microphone , uh , um procedures", "label": "fh|s^rt^t", "original_label": "fh|s^rt^t", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.G.dialogueact624", "speaker": "G", "starttime": "1185.73", "startwordid": "Bmr010.w.5,136", "endtime": "1187.29", "endwordid": "Bmr010.w.5,147", "text": "Well , let 's <disfmarker> why don't we talk about microphone issues ?", "label": "qo^cs", "original_label": "qo^cs", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "45a", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact678", "speaker": "G", "starttime": "1285.06", "startwordid": "Bmr010.w.5,589", "endtime": "1296.19", "endwordid": "Bmr010.w.5,618", "text": "But I <disfmarker> I think that it <disfmarker> it doesn't hurt , uh , the naturalness of the situation to try to have people <pause> wear the microphones properly , if possible ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.B.dialogueact706", "speaker": "B", "starttime": "1352.65", "startwordid": "Bmr010.w.5,862", "endtime": "1357.86", "endwordid": "Bmr010.w.5,881", "text": "So , anything to reduce breathing is <disfmarker> is <disfmarker> is a good thing .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c1"}}, {"id": "Bmr010.A.dialogueact711", "speaker": "A", "starttime": "1363.56", "startwordid": "Bmr010.w.5,910", "endtime": "1368.57", "endwordid": "Bmr010.w.5,937", "text": "So you want it enough to the side so that when you exhale through your nose , it doesn't <disfmarker> the wind doesn't hit the mike .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.4", "text": "And, finally, it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural, statistical approach, i.e. via the use of Markov models.", "type": "abstract"}, "extractive": [{"id": "Bmr010.G.dialogueact1305", "speaker": "G", "starttime": "2461.96", "startwordid": "Bmr010.w.10,962", "endtime": "2469.34", "endwordid": "Bmr010.w.10,987", "text": "But , I mean , the other things that we talked about is , uh , <vocalsound> pitch - related things and harmonicity - related things ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1318", "speaker": "G", "starttime": "2498.69", "startwordid": "Bmr010.w.11,102", "endtime": "2500.75", "endwordid": "Bmr010.w.11,111", "text": "You know , have a <disfmarker> have a couple Markov models", "label": "s^e", "original_label": "s^e", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1312", "speaker": "G", "starttime": "2483.76", "startwordid": "Bmr010.w.11,033", "endtime": "2487.19", "endwordid": "Bmr010.w.11,048", "text": "which is to say , don't worry so much about the , uh , features .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1321", "speaker": "G", "starttime": "2501.5", "startwordid": "Bmr010.w.11,117", "endtime": "2507.26", "endwordid": "Bmr010.w.11,149", "text": "and , uh , try to indi try to determine , you know , w when is th when are you in an overlap , when are you not in an overlap .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1323", "speaker": "G", "starttime": "2507.81", "startwordid": "Bmr010.w.11,152", "endtime": "2512.47", "endwordid": "Bmr010.w.11,173", "text": "And let the , uh , uh , statistical system <pause> determine what 's the right way to look at the data .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.D.dialogueact1353", "speaker": "D", "starttime": "2577.45", "startwordid": "Bmr010.w.11,424", "endtime": "2588.53", "endwordid": "Bmr010.w.11,466", "text": "And I hope the <disfmarker> the next week I will have , eh , some results and we <disfmarker> we will show <disfmarker> we will see , eh , the <disfmarker> the parameter <disfmarker> the pitch , <vocalsound> eh , tracking in <disfmarker> with the program .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn005", "adjacency": "6a", "channel": "c3"}}, {"id": "Bmr010.G.dialogueact1499", "speaker": "G", "starttime": "2805.92", "startwordid": "Bmr010.w.12,478", "endtime": "2812.1", "endwordid": "Bmr010.w.12,495", "text": "uh , the <disfmarker> has <disfmarker> has , uh , been exploring , uh , e largely the energy issue", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1488", "speaker": "G", "starttime": "2794.67", "startwordid": "Bmr010.w.12,431", "endtime": "2798.81", "endwordid": "Bmr010.disfmarker.688", "text": "So far , um , uh , Jose has <disfmarker> has been <disfmarker>", "label": "s.%--", "original_label": "s.%--", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1518", "speaker": "G", "starttime": "2851.77", "startwordid": "Bmr010.w.12,680", "endtime": "2858.28", "endwordid": "Bmr010.w.12,714", "text": "but it may be <disfmarker> given that you have a limited time here , it <disfmarker> it just may not be the best thing to <disfmarker> <vocalsound> to <disfmarker> to focus on for the remaining of it .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1528", "speaker": "G", "starttime": "2870.54", "startwordid": "Bmr010.w.12,768", "endtime": "2872.86", "endwordid": "Bmr010.w.12,777", "text": "Th - they were suggesting going to Markov models ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}]}, {"abstractive": {"id": "Bmr010.s.5", "text": "In the interest of time, it was decided that the group should continue using the existing Transcriber tool and perform a forced alignment on the close-talking microphones that will, it is hoped, help to recover some of the time information indicating where different speaker overlaps occurred in the signal.", "type": "decisions"}, "extractive": [{"id": "Bmr010.A.dialogueact322", "speaker": "A", "starttime": "659.925", "startwordid": "Bmr010.w.2,691", "endtime": "666.275", "endwordid": "Bmr010.w.2,715", "text": "What our decision was is that <pause> we 'll go ahead with what we have with a not very fine time scale on the overlaps .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "7a", "channel": "c0"}}, {"id": "Bmr010.F.dialogueact331", "speaker": "F", "starttime": "678.517", "startwordid": "Bmr010.w.2,771", "endtime": "686.989", "endwordid": "Bmr010.w.2,805", "text": "then <nonvocalsound> when they 're encoding the overlaps <nonvocalsound> it would be nice for them to be able to specify when <disfmarker> you know , the start points and end points of overlaps .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.A.dialogueact552", "speaker": "A", "starttime": "1079.74", "startwordid": "Bmr010.w.4,599", "endtime": "1090.38", "endwordid": "Bmr010.w.4,638", "text": "And I hope that if we do a forced alignment with the close - talking mike , that will be enough to recover at least some of the time the time information of when the overlap occurred .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "33a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.6", "text": "A meeting will be arranged with NIST to decide on a common standard and format for doing transcriptions.", "type": "decisions"}, "extractive": [{"id": "Bmr010.A.dialogueact440", "speaker": "A", "starttime": "867.02", "startwordid": "Bmr010.w.3,660", "endtime": "868.39", "endwordid": "Bmr010.w.3,669", "text": "Oh , we should definitely get with them then ,", "label": "fg|s", "original_label": "fg|s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c0"}}, {"id": "Bmr010.A.dialogueact442", "speaker": "A", "starttime": "870.51", "startwordid": "Bmr010.w.3,673", "endtime": "871.49", "endwordid": "Bmr010.w.3,677", "text": "agree upon a format .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.7", "text": "One or two meetings will be assigned to multiple transcribers to check for inter-annotator agreement.", "type": "decisions"}, "extractive": [{"id": "Bmr010.A.dialogueact1140", "speaker": "A", "starttime": "2120.16", "startwordid": "Bmr010.w.9,539", "endtime": "2125.41", "endwordid": "Bmr010.w.9,562", "text": "I think it would also be interesting to have , uh , a couple of the meetings have more than one transcriber do ,", "label": "s^cs^rt", "original_label": "s^cs^rt", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "21a", "channel": "c0"}}, {"id": "Bmr010.A.dialogueact1142", "speaker": "A", "starttime": "2126.01", "startwordid": "Bmr010.w.9,567", "endtime": "2128.16", "endwordid": "Bmr010.w.9,576", "text": "cuz I 'm curious about inter - annotator agreement .", "label": "s^df", "original_label": "s^df", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "21a+", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.8", "text": "To cut down on audible breaths during recordings, the group will institute some level of standards for microphone wear and use.", "type": "decisions"}, "extractive": [{"id": "Bmr010.G.dialogueact678", "speaker": "G", "starttime": "1285.06", "startwordid": "Bmr010.w.5,589", "endtime": "1296.19", "endwordid": "Bmr010.w.5,618", "text": "But I <disfmarker> I think that it <disfmarker> it doesn't hurt , uh , the naturalness of the situation to try to have people <pause> wear the microphones properly , if possible ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.B.dialogueact706", "speaker": "B", "starttime": "1352.65", "startwordid": "Bmr010.w.5,862", "endtime": "1357.86", "endwordid": "Bmr010.w.5,881", "text": "So , anything to reduce breathing is <disfmarker> is <disfmarker> is a good thing .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c1"}}, {"id": "Bmr010.A.dialogueact711", "speaker": "A", "starttime": "1363.56", "startwordid": "Bmr010.w.5,910", "endtime": "1368.57", "endwordid": "Bmr010.w.5,937", "text": "So you want it enough to the side so that when you exhale through your nose , it doesn't <disfmarker> the wind doesn't hit the mike .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.9", "text": "Speaker mn005 will feed his hand-segmented data into the speech segmenter developed by Javier to train it to identify different types of speech (i.e. that of single versus multiple speakers), as well as focussing on pitch- and harmonicity-related features for identifying overlapping speech.", "type": "decisions"}, "extractive": [{"id": "Bmr010.G.dialogueact1305", "speaker": "G", "starttime": "2461.96", "startwordid": "Bmr010.w.10,962", "endtime": "2469.34", "endwordid": "Bmr010.w.10,987", "text": "But , I mean , the other things that we talked about is , uh , <vocalsound> pitch - related things and harmonicity - related things ,", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.D.dialogueact1353", "speaker": "D", "starttime": "2577.45", "startwordid": "Bmr010.w.11,424", "endtime": "2588.53", "endwordid": "Bmr010.w.11,466", "text": "And I hope the <disfmarker> the next week I will have , eh , some results and we <disfmarker> we will show <disfmarker> we will see , eh , the <disfmarker> the parameter <disfmarker> the pitch , <vocalsound> eh , tracking in <disfmarker> with the program .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn005", "adjacency": "6a", "channel": "c3"}}, {"id": "Bmr010.D.dialogueact1537", "speaker": "D", "starttime": "2890.18", "startwordid": "Bmr010.w.12,849", "endtime": "2894.98", "endwordid": "Bmr010.w.12,865", "text": "But , eh , what did you think about the possibility of using the Javier software ?", "label": "qw", "original_label": "qw", "attributes": {"role": "PhD", "participant": "mn005", "channel": "c3"}}, {"id": "Bmr010.A.dialogueact1568", "speaker": "A", "starttime": "2989.76", "startwordid": "Bmr010.w.13,217", "endtime": "2996.1", "endwordid": "Bmr010.w.13,250", "text": "Right . So if we <disfmarker> if we fed the hand - segmentation to Javier 's and it doesn't work , then we know something 's wrong .", "label": "fg|s^cs", "original_label": "fg|s^cs", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "36a", "channel": "c0"}}, {"id": "Bmr010.A.dialogueact1574", "speaker": "A", "starttime": "2997.41", "startwordid": "Bmr010.w.13,268", "endtime": "2998.91", "endwordid": "Bmr010.w.13,277", "text": "Yeah . I think that 's probably worthwhile doing .", "label": "s^na", "original_label": "s^na", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "37b", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.10", "text": "There is no channel identifier to help in encoding speaker overlaps.", "type": "problems"}, "extractive": [{"id": "Bmr010.F.dialogueact501", "speaker": "F", "starttime": "980.892", "startwordid": "Bmr010.w.4,159", "endtime": "985.704", "endwordid": "Bmr010.w.4,180", "text": "Cuz there is one thing that we don't have right now and that is the automatic , um , channel identifier .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "26a", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact503", "speaker": "F", "starttime": "986.249", "startwordid": "Bmr010.w.4,185", "endtime": "989.729", "endwordid": "Bmr010.w.4,201", "text": "That <disfmarker> that , you know , that would g help in terms of encoding of overlaps .", "label": "s^rt", "original_label": "s^rt", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "26a+", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr010.s.11", "text": "Speech uttered while laughing is problematic for ASR.", "type": "problems"}, "extractive": [{"id": "Bmr010.B.dialogueact860", "speaker": "B", "starttime": "1606.39", "startwordid": "Bmr010.w.7,062", "endtime": "1611.39", "endwordid": "Bmr010.w.7,080", "text": "Well , the thing that you <disfmarker> is hard to deal with is whe <vocalsound> when they speak while laughing .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "adjacency": "19b.20a", "channel": "c1"}}]}, {"abstractive": {"id": "Bmr010.s.12", "text": "So far, speaker mn005's attempts to detect speaker overlap have been unsuccessful, as it has not been possible to normalize energy as a reliable indicator of overlap.", "type": "problems"}, "extractive": [{"id": "Bmr010.G.dialogueact1277", "speaker": "G", "starttime": "2418.26", "startwordid": "Bmr010.w.10,747", "endtime": "2421.03", "endwordid": "Bmr010.w.10,763", "text": "But the bottom line is it 's still not , uh , separating out very well .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "3a", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1488", "speaker": "G", "starttime": "2794.67", "startwordid": "Bmr010.w.12,431", "endtime": "2798.81", "endwordid": "Bmr010.disfmarker.688", "text": "So far , um , uh , Jose has <disfmarker> has been <disfmarker>", "label": "s.%--", "original_label": "s.%--", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}, {"id": "Bmr010.G.dialogueact1514", "speaker": "G", "starttime": "2842.25", "startwordid": "Bmr010.w.12,639", "endtime": "2847.56", "endwordid": "Bmr010.w.12,660", "text": "and <disfmarker> and so far at least has not come up with <vocalsound> any combination that really gave you an indicator .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}]}, {"abstractive": {"id": "Bmr010.s.13", "text": "Speaker mn014's efforts to detect speech/non-speech portions in the mixed signal (using an HMM-based detector with Gaussian mixtures) have produced pre-segmentations that facilitate the transcription effort.", "type": "progress"}, "extractive": [{"id": "Bmr010.F.dialogueact34", "speaker": "F", "starttime": "57.342", "startwordid": "Bmr010.w.224", "endtime": "62.932", "endwordid": "Bmr010.w.248", "text": "The <disfmarker> we have great <disfmarker> great , uh , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "7a", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact37", "speaker": "F", "starttime": "67.0", "startwordid": "Bmr010.w.258", "endtime": "68.85", "endwordid": "Bmr010.w.268", "text": "Well , it 's a <disfmarker> it 's a big improvement .", "label": "s^ba", "original_label": "s^ba", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "8b-2.9a", "channel": "c8"}}, {"id": "Bmr010.C.dialogueact122", "speaker": "C", "starttime": "245.001", "startwordid": "Bmr010.w.957", "endtime": "255.361", "endwordid": "Bmr010.w.984", "text": "Um , so , uh , what we basically did so far was using the mixed file to <disfmarker> to detect s speech or nonspeech <pause> portions in that .", "label": "h|s^rt", "original_label": "h|s^rt", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}, {"id": "Bmr010.C.dialogueact125", "speaker": "C", "starttime": "261.484", "startwordid": "Bmr010.w.1,004", "endtime": "266.794", "endwordid": "Bmr010.w.1,020", "text": "which is an HMM - ba based system with Gaussian mixtures for s speech and nonspeech .", "label": "s^e^rt", "original_label": "s^e^rt", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}, {"id": "Bmr010.C.dialogueact136", "speaker": "C", "starttime": "295.417", "startwordid": "Bmr010.w.1,113", "endtime": "298.457", "endwordid": "Bmr010.w.1,123", "text": "And I did some pre - segmentations for <disfmarker> for Jane .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}, {"id": "Bmr010.F.dialogueact140", "speaker": "F", "starttime": "305.335", "startwordid": "Bmr010.w.1,147", "endtime": "307.315", "endwordid": "Bmr010.w.1,157", "text": "Uh , they <disfmarker> they think it 's a terrific improvement .", "label": "s^na", "original_label": "s^na", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "25b", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact203", "speaker": "F", "starttime": "414.922", "startwordid": "Bmr010.w.1,587", "endtime": "417.012", "endwordid": "Bmr010.w.1,596", "text": "But <nonvocalsound> it <disfmarker> it saves so much time <disfmarker> the <disfmarker> the <nonvocalsound> transcribers", "label": "s^arp", "original_label": "s^arp", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "32b-2+.33a", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr010.s.14", "text": "Speaker mn014 also trained the system to identify speech from loud versus quiet speakers.", "type": "progress"}, "extractive": [{"id": "Bmr010.C.dialogueact151", "speaker": "C", "starttime": "331.957", "startwordid": "Bmr010.w.1,252", "endtime": "336.617", "endwordid": "Bmr010.w.1,270", "text": "And so I did two mixtures , one for the loud speakers and one for the quiet speakers .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}]}, {"abstractive": {"id": "Bmr010.s.15", "text": "Such pre-segmentation modifications allow the experimenter to specify the minimum length of speech and silence portions desired, and also facilitate the identification of pauses and utterance boundaries.", "type": "progress"}, "extractive": [{"id": "Bmr010.C.dialogueact179", "speaker": "C", "starttime": "379.243", "startwordid": "Bmr010.w.1,453", "endtime": "385.361", "endwordid": "Bmr010.w.1,468", "text": "You can specify <vocalsound> the minimum length of speech or <disfmarker> and silence portions which you want .", "label": "s^na", "original_label": "s^na", "attributes": {"role": "PhD", "participant": "mn014", "adjacency": "30b", "channel": "c2"}}, {"id": "Bmr010.C.dialogueact181", "speaker": "C", "starttime": "388.741", "startwordid": "Bmr010.w.1,480", "endtime": "394.68", "endwordid": "Bmr010.w.1,489", "text": "basically changing the minimum <disfmarker> minimum <pause> length for s for silence", "label": "s^e", "original_label": "s^e", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}, {"id": "Bmr010.A.dialogueact187", "speaker": "A", "starttime": "404.059", "startwordid": "Bmr010.w.1,514", "endtime": "409.726", "endwordid": "Bmr010.w.1,535", "text": "Right . So this would work well for , uh , pauses and utterance boundaries and things like that .", "label": "fg|s^bu", "original_label": "fg|s^bu", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "31a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.16", "text": "The transcriber pool is making quick progress, and may be used in the future to perform other types of coding, e.g. a more detailed analysis of speaker overlap.", "type": "progress"}, "extractive": [{"id": "Bmr010.F.dialogueact331", "speaker": "F", "starttime": "678.517", "startwordid": "Bmr010.w.2,771", "endtime": "686.989", "endwordid": "Bmr010.w.2,805", "text": "then <nonvocalsound> when they 're encoding the overlaps <nonvocalsound> it would be nice for them to be able to specify when <disfmarker> you know , the start points and end points of overlaps .", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact333", "speaker": "F", "starttime": "687.369", "startwordid": "Bmr010.w.2,806", "endtime": "689.239", "endwordid": "Bmr010.w.2,815", "text": "uh Th - they 're <nonvocalsound> making really quick progress .", "label": "s^ba", "original_label": "sj^ba", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "8a", "channel": "c8"}}, {"id": "Bmr010.G.dialogueact1044", "speaker": "G", "starttime": "1953.74", "startwordid": "Bmr010.w.8,698", "endtime": "1962.37", "endwordid": "Bmr010.w.8,724", "text": "The other thing we could do , actually , uh , is , uh , use them for a more detailed analysis of the overlaps .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "adjacency": "9b.10a", "channel": "cb"}}, {"id": "Bmr010.F.dialogueact1133", "speaker": "F", "starttime": "2113.03", "startwordid": "Bmr010.w.9,499", "endtime": "2117.04", "endwordid": "Bmr010.w.9,514", "text": "These people would be <nonvocalsound> great choices for doing coding of that type if we wanted ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr010.s.17", "text": "Transcribers are coding non-speech gestures, such as audible breaths and laughter, both of which are useful for improving recognition results.", "type": "progress"}, "extractive": [{"id": "Bmr010.F.dialogueact816", "speaker": "F", "starttime": "1533.21", "startwordid": "Bmr010.w.6,688", "endtime": "1536.81", "endwordid": "Bmr010.w.6,706", "text": "They 're putting <disfmarker> Eh , so in curly brackets they put \" inhale \" or \" breath \" .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "15a+", "channel": "c8"}}, {"id": "Bmr010.B.dialogueact805", "speaker": "B", "starttime": "1515.81", "startwordid": "Bmr010.w.6,625", "endtime": "1520.94", "endwordid": "Bmr010.w.6,639", "text": "It is useful to transcribe and then ultimately train models for things like breath ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c1"}}, {"id": "Bmr010.B.dialogueact806", "speaker": "B", "starttime": "1520.94", "startwordid": "Bmr010.w.6,640", "endtime": "1525.11", "endwordid": "Bmr010.w.6,657", "text": "and also laughter is very , very frequent and important to <disfmarker> <vocalsound> to model .", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn017", "channel": "c1"}}, {"id": "Bmr010.F.dialogueact820", "speaker": "F", "starttime": "1537.28", "startwordid": "Bmr010.w.6,711", "endtime": "1539.8", "endwordid": "Bmr010.w.6,723", "text": "It <disfmarker> they <disfmarker> and then in curly brackets they say \" laughter \" .", "label": "s^e", "original_label": "s^e", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr010.s.18", "text": "Recent modifications to the Transcriber tool allow transcribers to listen to speech from different channels, as well as helping to preserve portions of overlapping speech, and enabling the creation of different output files for each channel for a cleaner and more segmentable transcript.", "type": "progress"}, "extractive": [{"id": "Bmr010.F.dialogueact397", "speaker": "F", "starttime": "786.28", "startwordid": "Bmr010.w.3,321", "endtime": "793.255", "endwordid": "Bmr010.w.3,345", "text": "And <disfmarker> and , um , Dan Ellis 's hack already allows them to be <nonvocalsound> able to display <vocalsound> different <nonvocalsound> waveforms to clarify overlaps and things ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "15a+", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact403", "speaker": "F", "starttime": "803.256", "startwordid": "Bmr010.w.3,400", "endtime": "810.961", "endwordid": "Bmr010.w.3,421", "text": "And Dan Ellis 's hack handles the , <vocalsound> um , choice <nonvocalsound> <disfmarker> the ability to choose different waveforms <vocalsound> from moment to moment .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "adjacency": "17a", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact419", "speaker": "F", "starttime": "821.845", "startwordid": "Bmr010.w.3,487", "endtime": "827.61", "endwordid": "Bmr010.w.3,505", "text": "the hack to <vocalsound> preserve the overlaps <nonvocalsound> better would be one which creates different output files for each channel ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact423", "speaker": "F", "starttime": "832.451", "startwordid": "Bmr010.w.3,526", "endtime": "835.54", "endwordid": "Bmr010.w.3,538", "text": "separable , uh , cleanly , easily separable ,", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.F.dialogueact425", "speaker": "F", "starttime": "835.92", "startwordid": "Bmr010.w.3,539", "endtime": "838.94", "endwordid": "Bmr010.w.3,551", "text": "uh , transcript tied to a single channel , uh , audio .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}]}, {"abstractive": {"id": "Bmr010.s.19", "text": "The Praat software package was discussed as an alternative transcription tool capable of representing multiple channels of speech.", "type": "progress"}, "extractive": [{"id": "Bmr010.C.dialogueact268", "speaker": "C", "starttime": "579.285", "startwordid": "Bmr010.w.2,276", "endtime": "584.015", "endwordid": "Bmr010.w.2,288", "text": "which she uses to do eight channels , uh , trans transliterations ,", "label": "s", "original_label": "s", "attributes": {"role": "PhD", "participant": "mn014", "channel": "c2"}}, {"id": "Bmr010.F.dialogueact286", "speaker": "F", "starttime": "606.33", "startwordid": "Bmr010.w.2,408", "endtime": "610.64", "endwordid": "Bmr010.w.2,426", "text": "this <disfmarker> this is called Praat , PRAAT , <nonvocalsound> which I guess means spee speech in Dutch or something .", "label": "s", "original_label": "s", "attributes": {"role": "Postdoc", "participant": "fe008", "channel": "c8"}}, {"id": "Bmr010.A.dialogueact279", "speaker": "A", "starttime": "596.965", "startwordid": "Bmr010.w.2,356", "endtime": "597.945", "endwordid": "Bmr010.w.2,362", "text": "Well , maybe we should get it", "label": "s^cs", "original_label": "s^cs", "attributes": {"role": "Grad", "participant": "me011", "adjacency": "38a", "channel": "c0"}}]}, {"abstractive": {"id": "Bmr010.s.20", "text": "Cross-correlation was discussed as a means of enabling speaker identification, and may be integrated into future work.", "type": "progress"}, "extractive": [{"id": "Bmr010.A.dialogueact476", "speaker": "A", "starttime": "932.966", "startwordid": "Bmr010.w.3,955", "endtime": "933.696", "endwordid": "Bmr010.w.3,958", "text": "Cross - correlation .", "label": "s", "original_label": "s", "attributes": {"role": "Grad", "participant": "me011", "channel": "c0"}}, {"id": "Bmr010.G.dialogueact488", "speaker": "G", "starttime": "951.278", "startwordid": "Bmr010.w.4,042", "endtime": "958.418", "endwordid": "Bmr010.w.4,074", "text": "by doing that , you know , rather than setting any , uh , absolute threshold , you actually can do pretty good , uh , selection of who <disfmarker> who 's talking .", "label": "s", "original_label": "s", "attributes": {"role": "Professor", "participant": "me013", "channel": "cb"}}]}]