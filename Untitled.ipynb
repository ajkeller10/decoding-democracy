{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c728414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdp_backend.database import models as db_models\n",
    "from cdp_backend.pipeline.transcript_model import Transcript\n",
    "import fireo\n",
    "from gcsfs import GCSFileSystem\n",
    "from google.auth.credentials import AnonymousCredentials\n",
    "from google.cloud.firestore import Client\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc122b",
   "metadata": {},
   "source": [
    "# import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227640d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcripts.pickle\", \"rb\") as f:\n",
    "    transcripts = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0294039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transcripts: 412\n",
      "Number of sentencess: 328733\n",
      "Number of words: 4843941\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of transcripts: {len(transcripts)}\")\n",
    "print(f\"Number of sentencess: {sum([len(sentences) for sentences in transcripts.values()])}\")\n",
    "print(f\"Number of words: {sum([sum([len(sentence.split()) for sentence in sentences]) for sentences in transcripts.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f5b1bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=list(transcripts.keys())[0]\n",
    "transcripts[ex][-1]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e454511",
   "metadata": {},
   "source": [
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3301dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec44eb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>length</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0a7e5864959</td>\n",
       "      <td>[And older woman Jocasta Zamarripa., Shortly, ...</td>\n",
       "      <td>459</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e9a7a8ac9081</td>\n",
       "      <td>[Meeting., My name is Cavalier Johnson., I'm c...</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>694b0e5b01a7</td>\n",
       "      <td>[Joining you this morning is Vice Chair Alderm...</td>\n",
       "      <td>2242</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad734a167e5a</td>\n",
       "      <td>[Our first meeting of 2020, the Judiciary and ...</td>\n",
       "      <td>1473</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe845b99f32e</td>\n",
       "      <td>[Alderman Hamilton., Here., Kovach., Here., Ba...</td>\n",
       "      <td>1478</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>468bb3242311</td>\n",
       "      <td>[Commission for Tuesday September 1st 2020 at ...</td>\n",
       "      <td>1255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>16327f867c7e</td>\n",
       "      <td>[Our 2021 meeting of the Fire and Police Commi...</td>\n",
       "      <td>1208</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>ea6416ba848c</td>\n",
       "      <td>[Thank you, Mr. President., You know, my colle...</td>\n",
       "      <td>1619</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>d32da631854f</td>\n",
       "      <td>[This meeting will come to order, this council...</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>aeb4ca3154ba</td>\n",
       "      <td>[Sally Peltz?, Here., Nicholas Hans Robinson?,...</td>\n",
       "      <td>1986</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    transcript_id                                          sentences  length  \\\n",
       "0    d0a7e5864959  [And older woman Jocasta Zamarripa., Shortly, ...     459   \n",
       "1    e9a7a8ac9081  [Meeting., My name is Cavalier Johnson., I'm c...     155   \n",
       "2    694b0e5b01a7  [Joining you this morning is Vice Chair Alderm...    2242   \n",
       "3    ad734a167e5a  [Our first meeting of 2020, the Judiciary and ...    1473   \n",
       "4    fe845b99f32e  [Alderman Hamilton., Here., Kovach., Here., Ba...    1478   \n",
       "..            ...                                                ...     ...   \n",
       "407  468bb3242311  [Commission for Tuesday September 1st 2020 at ...    1255   \n",
       "408  16327f867c7e  [Our 2021 meeting of the Fire and Police Commi...    1208   \n",
       "409  ea6416ba848c  [Thank you, Mr. President., You know, my colle...    1619   \n",
       "410  d32da631854f  [This meeting will come to order, this council...     132   \n",
       "411  aeb4ca3154ba  [Sally Peltz?, Here., Nicholas Hans Robinson?,...    1986   \n",
       "\n",
       "       use  \n",
       "0     True  \n",
       "1    False  \n",
       "2     True  \n",
       "3     True  \n",
       "4     True  \n",
       "..     ...  \n",
       "407   True  \n",
       "408   True  \n",
       "409   True  \n",
       "410  False  \n",
       "411   True  \n",
       "\n",
       "[412 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame(transcripts.keys(),columns=[\"transcript_id\"])\n",
    "\n",
    "t['sentences']=t[\"transcript_id\"].apply(lambda x: transcripts[x])\n",
    "t['length']=t['sentences'].apply(lambda x: len(x)) \n",
    "t['use']=t['length']>=min_length\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41ad079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329, 412)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_long=t[t.use]\n",
    "\n",
    "len(t_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095c645",
   "metadata": {},
   "source": [
    "# generate segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90182f47",
   "metadata": {},
   "source": [
    "probably better not to do this as pd. instead do it as [] opps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "aa08bedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-integer stop for randrange()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/random.py:325\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     istop \u001b[38;5;241m=\u001b[39m \u001b[43m_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[252], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m     text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mtext\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m*\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences_to_use\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m---> 58\u001b[0m \u001b[43mgenerate_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtranscripts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdoc_count_limit\u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msentence_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[0;32mIn[252], line 40\u001b[0m, in \u001b[0;36mgenerate_segment\u001b[0;34m(t, doc_count_limit, sentence_min)\u001b[0m\n\u001b[1;32m     37\u001b[0m sentences_to_use \u001b[38;5;241m=\u001b[39m (lengths \u001b[38;5;241m*\u001b[39m doc_percents) \u001b[38;5;241m+\u001b[39m sentence_min\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#where to start \u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m sentences_start\u001b[38;5;241m=\u001b[39m[random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m\u001b[38;5;241m-\u001b[39msen) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m, sen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lengths,sentences_to_use)]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc_percents\n\u001b[1;32m     44\u001b[0m text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences_to_use\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39msentence_min) \u001b[38;5;241m*\u001b[39m sentences_distributed \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(sentences_distributed)\n",
      "Cell \u001b[0;32mIn[252], line 40\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m sentences_to_use \u001b[38;5;241m=\u001b[39m (lengths \u001b[38;5;241m*\u001b[39m doc_percents) \u001b[38;5;241m+\u001b[39m sentence_min\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#where to start \u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m sentences_start\u001b[38;5;241m=\u001b[39m[\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43msen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m, sen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lengths,sentences_to_use)]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc_percents\n\u001b[1;32m     44\u001b[0m text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences_to_use\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39msentence_min) \u001b[38;5;241m*\u001b[39m sentences_distributed \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(sentences_distributed)\n",
      "File \u001b[0;32m/usr/lib/python3.10/random.py:370\u001b[0m, in \u001b[0;36mRandom.randint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/random.py:331\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m istop \u001b[38;5;241m!=\u001b[39m stop:\n\u001b[1;32m    329\u001b[0m         _warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandrange() will raise TypeError in the future\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    330\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-integer stop for randrange()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    332\u001b[0m     _warn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-integer arguments to randrange() have been deprecated \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msince Python 3.10 and will be removed in a subsequent \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    334\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    335\u001b[0m           \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    336\u001b[0m width \u001b[38;5;241m=\u001b[39m istop \u001b[38;5;241m-\u001b[39m istart\n",
      "\u001b[0;31mValueError\u001b[0m: non-integer stop for randrange()"
     ]
    }
   ],
   "source": [
    "def generate_segment(t: list, doc_count_limit: int = 10, sentence_min: int = 20) -> tuple: \n",
    "    '''\n",
    "    generate text segment from transcript data\n",
    "    \n",
    "    Args:\n",
    "        t: list of transcripts\n",
    "        doc_count_limit: maximum number of docs to pull from\n",
    "        sentence_min: minimum number of sentences per text\n",
    "    \n",
    "    Returns:\n",
    "        segment (list): List of sentences\n",
    "        labels (list): Number document sentence pulled from \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #filter text for sufficiently long texts\n",
    "    t_long=list(filter(lambda transcript: len(transcript) >= (sentence_min * doc_count_limit), t))\n",
    "    \n",
    "    #count of documents\n",
    "    doc_count = random.randint(1,doc_count_limit)\n",
    "    \n",
    "    #pull random docs based on document count\n",
    "    docs = random.sample(t_long,doc_count)\n",
    "       \n",
    "    #distribute sentences between documents - based on percentage of original length\n",
    "    doc_percents = np.random.randint(100, size=doc_count)\n",
    "    doc_percents = doc_percents / sum(doc_percents)\n",
    "    \n",
    "    #sentence count per doc\n",
    "    lengths = np.array([len(doc) for doc in docs])\n",
    "    sentences_to_use = (lengths * doc_percents) + sentence_min\n",
    "    \n",
    "    #where to start \n",
    "    sentences_start=[random.randint(0, len-sen) for len, sen in zip(lengths,sentences_to_use)]\n",
    "    \n",
    "    return doc_percents\n",
    "    \n",
    "    text['sentences_to_use'] = (text['length']-sentence_min) * sentences_distributed / sum(sentences_distributed)\n",
    "    text['sentences_to_use']= text['sentences_to_use'].astype('int') + sentence_min\n",
    "    \n",
    "    #decide where to pull the sentences from \n",
    "    text['sentences_start']=text.apply(lambda x: random.randint(0,x['length']-x['sentences_to_use']),axis=1)\n",
    "        \n",
    "    #NOTE: should the first segment start at 0, and the last end at -1?\n",
    "       \n",
    "    #get sentences\n",
    "    text['result']=text.apply(lambda x: x['sentences'][x.sentences_start:(x.sentences_start+x.sentences_to_use)],axis=1) #)\n",
    "    text['labels']=text.apply(lambda x: [x['index']] * x['sentences_to_use'],axis=1)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "generate_segment(list(transcripts.values()),doc_count_limit:=10,sentence_min=20)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8a09c123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>length</th>\n",
       "      <th>use</th>\n",
       "      <th>sentences_to_use</th>\n",
       "      <th>sentences_start</th>\n",
       "      <th>result</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>350ce606b3d7</td>\n",
       "      <td>[Okay., Welcome everyone., My name is Stephani...</td>\n",
       "      <td>1343</td>\n",
       "      <td>True</td>\n",
       "      <td>164</td>\n",
       "      <td>418</td>\n",
       "      <td>[Just so people know, if you do want to ask qu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20df22a68c59</td>\n",
       "      <td>[Good afternoon, I'd like to welcome you all t...</td>\n",
       "      <td>1172</td>\n",
       "      <td>True</td>\n",
       "      <td>313</td>\n",
       "      <td>340</td>\n",
       "      <td>[We have leased 4,200 square feet., It's proba...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65eb77fc998c</td>\n",
       "      <td>[. To order this meeting of the common council...</td>\n",
       "      <td>1402</td>\n",
       "      <td>True</td>\n",
       "      <td>685</td>\n",
       "      <td>347</td>\n",
       "      <td>[Hagee. Hagee., Hagee. Angie, Hagee. This is a...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8e9bb9f30309</td>\n",
       "      <td>[Through your patience, we have technical issu...</td>\n",
       "      <td>423</td>\n",
       "      <td>True</td>\n",
       "      <td>82</td>\n",
       "      <td>63</td>\n",
       "      <td>[Item 3, FPC 20298, resolution regarding ACLU ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index transcript_id                                          sentences  \\\n",
       "0      0  350ce606b3d7  [Okay., Welcome everyone., My name is Stephani...   \n",
       "1      1  20df22a68c59  [Good afternoon, I'd like to welcome you all t...   \n",
       "2      2  65eb77fc998c  [. To order this meeting of the common council...   \n",
       "3      3  8e9bb9f30309  [Through your patience, we have technical issu...   \n",
       "\n",
       "   length   use  sentences_to_use  sentences_start  \\\n",
       "0    1343  True               164              418   \n",
       "1    1172  True               313              340   \n",
       "2    1402  True               685              347   \n",
       "3     423  True                82               63   \n",
       "\n",
       "                                              result  \\\n",
       "0  [Just so people know, if you do want to ask qu...   \n",
       "1  [We have leased 4,200 square feet., It's proba...   \n",
       "2  [Hagee. Hagee., Hagee. Angie, Hagee. This is a...   \n",
       "3  [Item 3, FPC 20298, resolution regarding ACLU ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_segment(t, doc_count_limit: int = 10, sentence_min: int = 20) -> tuple: \n",
    "    '''\n",
    "    generate text segment from transcript data\n",
    "    \n",
    "    Args:\n",
    "        doc_count_limit: maximum number of docs to pull from\n",
    "        sentence_min: minimum number of sentences per text\n",
    "    \n",
    "    Returns:\n",
    "        segment (list): List of sentences\n",
    "        labels (list): Number document sentence pulled from \n",
    "    \n",
    "    '''\n",
    "\n",
    "    #filter text for sufficiently long texts\n",
    "    t_long=t[t['length']>=(doc_count_limit*sentence_min)]\n",
    "\n",
    "    #count of documents\n",
    "    doc_count = random.randint(1,doc_count_limit)\n",
    "    \n",
    "    #pull text based on document count\n",
    "    text = t_long.sample(doc_count)\n",
    "    \n",
    "    #add row number as index and then index column\n",
    "    text.reset_index(inplace=True,drop=True)\n",
    "    text.reset_index(inplace=True)\n",
    "\n",
    "    \n",
    "    #get last length\n",
    "    length_sequence = text.iat[-1,int(text.columns.get_indexer(['length']))]\n",
    "    \n",
    "    # number of sentences to choose from between the documents\n",
    "    sentences_to_choose = length_sequence - (sentence_min * doc_count)\n",
    "    \n",
    "    #distribute sentences between documents - based on percentage of original length\n",
    "    sentences_distributed = np.random.randint(100, size=doc_count)\n",
    "    text['sentences_to_use'] = (text['length']-sentence_min) * sentences_distributed / sum(sentences_distributed)\n",
    "    text['sentences_to_use']= text['sentences_to_use'].astype('int') + sentence_min\n",
    "    \n",
    "    #decide where to pull the sentences from \n",
    "    text['sentences_start']=text.apply(lambda x: random.randint(0,x['length']-x['sentences_to_use']),axis=1)\n",
    "        \n",
    "    #NOTE: should the first segment start at 0, and the last end at -1?\n",
    "       \n",
    "    #get sentences\n",
    "    text['result']=text.apply(lambda x: x['sentences'][x.sentences_start:(x.sentences_start+x.sentences_to_use)],axis=1) #)\n",
    "    text['labels']=text.apply(lambda x: [x['index']] * x['sentences_to_use'],axis=1)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "generate_segment(t_long,10)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b778eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
